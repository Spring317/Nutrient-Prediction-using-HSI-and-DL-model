{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import imagecodecs\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.ops import Conv2dNormActivation\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchbearer\n",
    "from torchbearer import Trial\n",
    "from torchbearer.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_PATCH_SIZE = 320\n",
    "def get_patches_not_random(x_dict, y_dict, size=DEFAULT_PATCH_SIZE, num_patches=800):\n",
    "    x =[]\n",
    "    y = []\n",
    "    total_patches = 0\n",
    "    print(\"Generating patches\")\n",
    "    \n",
    "    for i in range(0,1):\n",
    "        \n",
    "        img  = x_dict[i]\n",
    "        mask = y_dict[i]\n",
    "        # img = list(x_dict)\n",
    "        # mask = list(y_dict)\n",
    "        img_height = img.shape[1]\n",
    "        img_width =  img.shape[2]\n",
    "        img_nb_channels = img.shape[0]\n",
    "        \n",
    "        mask_height = mask.shape[1]\n",
    "        mask_width =  mask.shape[2]\n",
    "        mask_nb_channels = mask.shape[0]\n",
    "        \n",
    "        device = \"cuda:0\"\n",
    "        # while total_patches < num_patches:\n",
    "        img_nb_patches_vertical = math.ceil(img_height / size)\n",
    "        img_nb_patches_horizontal = math.ceil(img_width / size)\n",
    "        img_extended_height = size * img_nb_patches_vertical\n",
    "        img_extended_width = size * img_nb_patches_horizontal\n",
    "    \n",
    "        mask_nb_patches_vertical = math.ceil(mask_height / size)\n",
    "        mask_nb_patches_horizontal = math.ceil(mask_width / size)\n",
    "        mask_extended_height = size * mask_nb_patches_vertical\n",
    "        mask_extended_width = size * mask_nb_patches_horizontal\n",
    "        \n",
    "        ext_x = np.zeros((img_nb_channels, img_extended_height, img_extended_width), dtype=np.float32)\n",
    "        ext_y = np.zeros((mask_nb_channels, mask_extended_height, mask_extended_width), dtype=np.float32)\n",
    "        ext_x[:, :img_height, :img_width] = img\n",
    "        ext_y[:, :mask_height, :mask_width]  = mask\n",
    "        for i in range(img_height, img_extended_height):\n",
    "            mirror_i = img_height - (i - img_height) % img_height - 1\n",
    "            ext_x[:, i, :] = ext_x[:, mirror_i, :]\n",
    "    \n",
    "        for j in range(img_width, img_extended_width):\n",
    "            mirror_j = img_width - (j - img_width) % img_width - 1\n",
    "            ext_x[:, :, j] = ext_x[:, :, mirror_j]\n",
    "        \n",
    "        for i in range(mask_height, mask_extended_height):\n",
    "            mirror_i = mask_height - (i - mask_height) % mask_height - 1\n",
    "            ext_y[:, i, :] = ext_y[:, mirror_i, :]\n",
    "    \n",
    "        for j in range(mask_width, mask_extended_width):\n",
    "            mirror_j = mask_width - (j - mask_width) % mask_width - 1\n",
    "            ext_y[:, :, j] = ext_y[:, :, mirror_j]  \n",
    "            \n",
    "        for i in range(img_nb_patches_vertical):\n",
    "            for j in range(img_nb_patches_horizontal):\n",
    "                x0, x1 = i * size, (i + 1) * size\n",
    "                y0, y1 = j * size, (j + 1) * size\n",
    "                x.append(ext_x[:, x0:x1, y0:y1])\n",
    "                y.append(ext_y[:, x0:x1, y0:y1])\n",
    "                total_patches += 1\n",
    "        \n",
    "                # print(f\"generating {total_patches} patches\")\n",
    "        print(\"Generated {} patches\".format(total_patches))\n",
    "    \n",
    "    return np.array(x, dtype= \"float32\"), np.array(y, dtype= \"float32\")               \n",
    "            # print(x,y)\n",
    "            # return np.array(x), np.array(y)\n",
    "            # yprime=list(map(str,y))\n",
    "            # new_y=\"\".join(yprime)\n",
    "            # new_y=new_y.replace(\"[]\",\"\")\n",
    "            # new_y=list(map(int,new_y))\n",
    "       \n",
    "        # return torch.FloatTensor(x), torch.FloatTensor(y)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "Returns a random augmented patch from the image\n",
    "\n",
    "img:     numpy array of shape (x_size, y_size, nb_channels)\n",
    "mask:    binary (one-hot) numpy array of shape (x_size, y_size, nb_classes)\n",
    "size:    size of random patch (square)\n",
    "\n",
    "returns: patch with shape(size, size, nb_channels) and its mask\n",
    "\"\"\"\n",
    "\n",
    "# def add_random_brightness(image, brightness_range=0.2):\n",
    "#     factor = 1 + np.random.uniform(-brightness_range, brightness_range)\n",
    "#     return np.clip(image * factor, 0, 255)\n",
    "\n",
    "# def add_random_contrast(image, contrast_range=0.2):\n",
    "#     mean = np.mean(image)\n",
    "#     factor = 1 + np.random.uniform(-contrast_range, contrast_range)\n",
    "#     return np.clip((image - mean) * factor + mean, 0, 255)\n",
    "\n",
    "# def add_gaussian_blur(image, max_kernel_size=5):\n",
    "#     if np.random.rand() < 0.5:\n",
    "#         kernel_size = np.random.choice(range(1, max_kernel_size, 2))\n",
    "#         image = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "#     return image\n",
    "\n",
    "# def add_random_noise(image, noise_factor=0.05):\n",
    "#     noise = np.random.randn(*image.shape) * noise_factor\n",
    "#     return np.clip(image + noise, 0, 255)\n",
    "\n",
    "def get_rand_patch(img, mask, size=DEFAULT_PATCH_SIZE):\n",
    "    # assert len(img.shape) == 3     \\\n",
    "    #        and img.shape[0] > size \\\n",
    "    #        and img.shape[1] > size \\\n",
    "    #        and img.shape[0:2] == mask.shape[0:2]\n",
    "\n",
    "    # SpaceNet images have 8 bands, we take only 3\n",
    "\n",
    "    xs = random.randint(0, abs(img.shape[0] - size))\n",
    "    ys = random.randint(0, abs(img.shape[1] - size))\n",
    "    # print(xs,ys)\n",
    "    patch_img  = img[:,xs:xs+size, ys:ys+size]\n",
    "    patch_mask = mask[:,xs:xs+size, ys:ys+size]\n",
    "\n",
    "    # # apply random transformations\n",
    "    # rt = np.random.randint(0, 7)\n",
    "    # if rt == 0:\n",
    "    #     # horizontal flip\n",
    "    #     patch_img  = patch_img[::-1, :, :]\n",
    "    #     patch_mask = patch_mask[::-1, :, :]\n",
    "    # elif rt == 1:\n",
    "    #     # vertical flip\n",
    "    #     patch_img  = patch_img[:, ::-1, :]\n",
    "    #     patch_mask = patch_mask[:, ::-1, :]\n",
    "    # elif rt == 2:\n",
    "    #     # transpose\n",
    "    #     patch_img = patch_img.transpose([1, 0, 2])\n",
    "    #     patch_mask = patch_mask.transpose([1, 0, 2])\n",
    "    # elif rt == 3:\n",
    "    #     # 90 degree rotation\n",
    "    #     patch_img = np.rot90(patch_img, 1)\n",
    "    #     patch_mask = np.rot90(patch_mask, 1)\n",
    "    # elif rt == 4:\n",
    "    #     # 180 degree rotation\n",
    "    #     patch_img = np.rot90(patch_img, 2)\n",
    "    #     patch_mask = np.rot90(patch_mask, 2)\n",
    "    # elif rt == 5:\n",
    "    #     # 270 degree rotation\n",
    "    #     patch_img = np.rot90(patch_img, 3)\n",
    "    #     patch_mask = np.rot90(patch_mask, 3)\n",
    "    # else:\n",
    "    #     # no transformation\n",
    "    #     pass\n",
    "    # # if np.random.rand() < 0.5: # 50% chance to apply brightness adjustment\n",
    "    #     patch_img = add_random_brightness(patch_img)\n",
    "\n",
    "    # if np.random.rand() < 0.5: # 50% chance to apply contrast adjustment\n",
    "    #     patch_img = add_random_contrast(patch_img)\n",
    "\n",
    "    # if np.random.rand() < 0.5: # 50% chance to apply Gaussian blur\n",
    "    #     patch_img = add_gaussian_blur(patch_img)\n",
    "\n",
    "    # if np.random.rand() < 0.5: # 50% chance to apply random noise\n",
    "    #     patch_img = add_random_noise(patch_img)\n",
    "    \n",
    "    # print(patch_img.shape, patch_mask.shape, mask.shape)\n",
    "    return patch_img.tolist(), patch_mask.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "returns specified number of patches\n",
    "\n",
    "x_dict:     (input) image dictionary (image_id -> image)\n",
    "y_dict:     (output) mask dictionary (image_id -> image)\n",
    "nb_pathces: number of patches to return\n",
    "size:       size of patches\n",
    "\n",
    "returns:    x and y, both numpy arrays of shape\n",
    "            (nb_patches, patch_size, patch_size, nb_channels)\n",
    "\"\"\"\n",
    "def get_patches(x_dict, y_dict, nb_patches, size=DEFAULT_PATCH_SIZE):\n",
    "    x =[]\n",
    "    y = []\n",
    "    total_patches = 0\n",
    "    print(\"Generating patches\")\n",
    "    while total_patches < nb_patches:\n",
    "        img_id = random.sample(x_dict.keys(), 1)[0]\n",
    "        img  = x_dict[img_id]\n",
    "        mask = y_dict[img_id]\n",
    "        # img = list(x_dict)\n",
    "        # mask = list(y_dict)\n",
    "        img_patch, mask_patch = get_rand_patch(img, mask, size)\n",
    "         \n",
    "        x.append(img_patch)\n",
    "        y.append(mask_patch)\n",
    "        total_patches += 1\n",
    "        \n",
    "        # print(f\"generating {total_patches} patches\")\n",
    "    \n",
    "    print(\"Generated {} patches\".format(total_patches))\n",
    "    # print(x,y)\n",
    "    # return np.array(x), np.array(y)\n",
    "    # yprime=list(map(str,y))\n",
    "    # new_y=\"\".join(yprime)\n",
    "    # new_y=new_y.replace(\"[]\",\"\")\n",
    "    # new_y=list(map(int,new_y))\n",
    "    return np.array(x, dtype= \"float32\"), np.array(y, dtype= \"float32\")\n",
    "    # return torch.FloatTensor(x), torch.FloatTensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        out = self.softmax(logits)\n",
    "        return out\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeeplabV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "\n",
    "class MobileNetV3_Segmentation(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels=122):\n",
    "        super(MobileNetV3_Segmentation, self).__init__()\n",
    "        # Load the MobileNetV3 model\n",
    "        mobilenet_v3 = models.mobilenet_v3_large(pretrained=True)\n",
    "        \n",
    "        # Modify the first convolution layer to accept input_channels\n",
    "        self.features = mobilenet_v3.features\n",
    "        self.features[0][0] = nn.Conv2d(input_channels, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "        \n",
    "        # Define the decoder part\n",
    "        self.decoder = DeepLabHead(960, num_classes)  # 960 is the output channels of the last conv layer of MobileNetV3\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Define the input and output dimensions\n",
    "# batch_num = 1  # Batch size\n",
    "# input_channels = 122\n",
    "# height = 224\n",
    "# width = 224\n",
    "# num_classes =   # Number of segmentation classes (including background)\n",
    "\n",
    "# # Initialize the model\n",
    "# model = MobileNetV3_Segmentation(num_classes, input_channels)\n",
    "\n",
    "# # Test the model with a dummy input\n",
    "\n",
    "# print(f\"Logits shape: {logits.shape}\")  # Shape: [batch_num, num_classes, height, width]\n",
    "\n",
    "# # Apply softmax to get probabilities (optional, for inference purposes)\n",
    "# probabilities = nn.functional.softmax(logits, dim=1)\n",
    "# print(f\"Probabilities shape: {probabilities.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "def cut_polygon_from_image(image, points, angle):\n",
    "    # Ensure we have exactly four points\n",
    "    if len(points) != 4:\n",
    "        raise ValueError(\"There must be exactly 4 points provided\")\n",
    "    \n",
    "    # Load the image\n",
    "    # image = cv2.imread(image_path)\n",
    "    # if image is None:\n",
    "    #     raise ValueError(f\"Image not found at path: {image_path}\")\n",
    "\n",
    "    # Convert the points to a numpy array of int32 type\n",
    "    pts = np.array(points, dtype=\"int32\")\n",
    "\n",
    "    # Create a mask with the same dimensions as the image\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    # Fill the polygon on the mask\n",
    "    cv2.fillPoly(mask, [pts], 255)\n",
    "\n",
    "    # Apply the mask to the image\n",
    "    masked_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Extract the bounding box of the polygon\n",
    "    rect = cv2.boundingRect(pts)\n",
    "    x, y, w, h = rect\n",
    "    \n",
    "    # Crop the masked image to the bounding box\n",
    "    cropped_image = masked_image[y:y+h, x:x+w]\n",
    "    image = imutils.rotate(cropped_image, angle=angle)\n",
    "    return image\n",
    "\n",
    "# Example usage\n",
    "# image_path = \"C:/Users/stdso/OneDrive/Pictures/1.jpg\"\n",
    "# points = [(100, 150), (480, 130), (396, 253), (120, 350)] \n",
    "\n",
    "# cut_image = cut_polygon_from_image(image_path, points)\n",
    "\n",
    "# def cut_and_rotate_polygon_from_image(image, points, angle):\n",
    "#     # Ensure we have exactly four points\n",
    "#     if len(points) != 4:\n",
    "#         raise ValueError(\"There must be exactly 4 points provided\")\n",
    "    \n",
    "#     # Convert the points to a numpy array of int32 type\n",
    "#     pts = np.array(points, dtype=\"int32\")\n",
    "\n",
    "#     # Compute the bounding box of the polygon\n",
    "#     rect = cv2.minAreaRect(pts)\n",
    "#     box = cv2.boxPoints(rect)\n",
    "#     box = np.int0(box)\n",
    "\n",
    "#     # Compute the center of the bounding box\n",
    "#     center = (int(rect[0][0]), int(rect[0][1]))\n",
    "\n",
    "#     # Compute the rotation matrix\n",
    "#     M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "#     # Rotate the entire image\n",
    "#     rotated_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "#     # Rotate the polygon points\n",
    "#     rotated_pts = cv2.transform(np.array([pts]), M)[0]\n",
    "\n",
    "#     # Create a mask with the same dimensions as the rotated image\n",
    "#     mask = np.zeros(rotated_image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "#     # Fill the polygon on the mask\n",
    "#     cv2.fillPoly(mask, [rotated_pts], 255)\n",
    "\n",
    "#     # Apply the mask to the rotated image\n",
    "#     masked_image = cv2.bitwise_and(rotated_image, rotated_image, mask=mask)\n",
    "\n",
    "#     # Extract the bounding box of the rotated polygon\n",
    "#     rect = cv2.boundingRect(rotated_pts)\n",
    "#     x, y, w, h = rect\n",
    "\n",
    "#     # Crop the masked image to the bounding box\n",
    "#     cropped_image = masked_image[y:y+h, x:x+w]\n",
    "\n",
    "#     return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example: Let's assume 'image' is a 3D numpy array with shape (height, width, 122)\n",
    "\n",
    "def reduce_channels(image, n_components=30):\n",
    "    num_channels, height, width= image.shape\n",
    "    assert num_channels == 122, \"The input image must have 122 channels\"\n",
    "\n",
    "    # Step 1: Flatten the image channels\n",
    "    flattened_image = image.reshape(-1, num_channels)\n",
    "    \n",
    "    # Step 2: Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    standardized_data = scaler.fit_transform(flattened_image)\n",
    "    \n",
    "    # Step 3: Apply PCA\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_data = pca.fit_transform(standardized_data)\n",
    "    \n",
    "    # Step 4: Reshape the data back to image shape\n",
    "    reduced_image = reduced_data.reshape(n_components, height, width)\n",
    "    \n",
    "    return reduced_image\n",
    "\n",
    "# Example usage with a mock image\n",
    "# image = np.random.rand(100, 100, 122)  # Replace with the actual image\n",
    "# reduced_image = reduce_channels(image, n_components=30)\n",
    "\n",
    "# If you have a specific image, load it and apply the function\n",
    "# For example, using OpenCV to read an image:\n",
    "# import cv2\n",
    "# image = cv2.imread('path_to_image')  # This needs to be replaced with actual image loading\n",
    "# reduced_image = reduce_channels(image, n_components=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize(img):\n",
    "#     # minv = img.min()\n",
    "#     maxv = img.max()\n",
    "#     print(maxv)\n",
    "#     return img / maxv\n",
    "img_dict = {}\n",
    "mask_dict = {}\n",
    "def normalize(img):\n",
    "    \"\"\"this function normalize the pixels in range (0,1)\"\"\"\n",
    "    min = img.min()\n",
    "    max = img.max()\n",
    "    x = 1/(max-min)\n",
    "    img = (img-min)*x\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 543. GiB for an array with shape (122, 122, 2750, 1780) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# cropped_mask =cut_polygon_from_image(mask[k],corners, 57)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     mask_list\u001b[38;5;241m.\u001b[39mappend(mask)\n\u001b[0;32m---> 18\u001b[0m img_dict[i] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m mask_dict[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(mask_list)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# img_dict[i] = cropped_img\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# mask_dict[i] = cropped_mask\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# tiff.imwrite('label1_cropped.tif', np.array(mask_list))\u001b[39;00m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 543. GiB for an array with shape (122, 122, 2750, 1780) and data type float64"
     ]
    }
   ],
   "source": [
    "# corners = [(3428.260869565217, 0.0), (4463.043478260869, 1440.8478260869567), (1436.9565217391305, 3419.108695652174), (345.6521739130435, 1962.5869565217392)]\n",
    "# for i in range(1,3):\n",
    "i = 0 \n",
    "img = normalize(tiff.imread(f'train4.tif'))\n",
    "mask = tiff.imread(\"label4.tif\")\n",
    "# print(img, mask)\n",
    "img_list= []\n",
    "mask_list= []\n",
    "for j in range(img.shape[0]):\n",
    "    # cropped_img = transform_image(img[i], corners)\n",
    "    # cropped_img = cut_polygon_from_image(img[j], corners, 57)\n",
    "    img_list.append(img)\n",
    "# tiff.imwrite('train1_cropped.tif', np.array(img_list))\n",
    "\n",
    "for k in range(mask.shape[0]):\n",
    "    # cropped_mask =cut_polygon_from_image(mask[k],corners, 57)\n",
    "    mask_list.append(mask)\n",
    "img_dict[i] = np.array(img_list)\n",
    "mask_dict[i] = np.array(mask_list)\n",
    "    # img_dict[i] = cropped_img\n",
    "    # mask_dict[i] = cropped_mask\n",
    "# tiff.imwrite('label1_cropped.tif', np.array(mask_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tiff.imread('/storage/student5/xuan_quy/HSI/train4.tif')\n",
    "mask = tiff.imread('/storage/student5/xuan_quy/HSI/label4.tif')\n",
    "# print(image.shape, mask.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n"
     ]
    }
   ],
   "source": [
    "# i = 1 \n",
    "# img = normalize(tiff.imread(f'datas/image/train{i+1}.tif'))\n",
    "# mask = tiff.imread(f\"datas/label/test{i+1}.tif\")\n",
    "# # print(img, mask)\n",
    "# corners = [(4577.5, 1469.3333333333333), (5585.833333333334, 2952.666666666667), (2277.5, 5127.666666666667), (1094.166666666667, 3577.666666666667)]\n",
    "# img_list= []\n",
    "# mask_list= []\n",
    "# for j in range(img.shape[0]):\n",
    "#     # cropped_img = transform_image(img[i], corners)\n",
    "#     cropped_img = cut_polygon_from_image(img[j], corners, 57)\n",
    "#     img_list.append(cropped_img)\n",
    "# # tiff.imwrite('train1_cropped.tif', np.array(img_list))\n",
    "\n",
    "# for k in range(mask.shape[0]):\n",
    "#     cropped_mask =cut_polygon_from_image(mask[k],corners, 57)\n",
    "#     mask_list.append(cropped_mask)\n",
    "\n",
    "# # img = np.array(img_list)\n",
    "# img_dict[i] = np.array(img_list)\n",
    "# mask_dict[i] = np.array(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 2 \n",
    "# img = normalize(tiff.imread(f'datas/image/train{i+1}.tif'))\n",
    "# mask = tiff.imread(f\"datas/label/test{i+1}.tif\")\n",
    "# # print(img, mask)\n",
    "# corners = [(4880.962962962963, 1596.2962962962963), (6269.851851851851,2774.074074074074), (3282.7058823529414, 7029.14705882353), (1788.588235294118,\n",
    "#           5923.264705882353)]\n",
    "# img_list= []\n",
    "# mask_list= []\n",
    "# for j in range(img.shape[0]):\n",
    "#     # cropped_img = transform_image(img[i], corners)\n",
    "#     cropped_img = cut_polygon_from_image(img[j], corners, 37)\n",
    "#     img_list.append(cropped_img)\n",
    "# # tiff.imwrite('train1_cropped.tif', np.array(img_list))\n",
    "\n",
    "# for k in range(mask.shape[0]):\n",
    "#     cropped_mask =cut_polygon_from_image(mask[k],corners, 37)\n",
    "#     mask_list.append(cropped_mask)\n",
    "\n",
    "# img_dict[i] = np.array(img_list)\n",
    "# mask_dict[i] = np.array(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 3 \n",
    "# img = normalize(tiff.imread(f'datas/image/train{i+1}.tif'))\n",
    "# mask = tiff.imread(f\"datas/label/test{i+1}.tif\")\n",
    "# # print(img, mask)\n",
    "# corners = [(4296.296296296296, 1566.6296296296296), (5693.736842105263, 2710.5263157894738), (2656.8947368421054, 7063.157894736842), (1120.0526315789475, 5984.210526315789)]\n",
    "# img_list= []\n",
    "# mask_list= []\n",
    "# for j in range(img.shape[0]):\n",
    "#     # cropped_img = transform_image(img[i], corners)\n",
    "#     cropped_img = cut_polygon_from_image(img[j], corners, 37)\n",
    "#     img_list.append(cropped_img)\n",
    "# # tiff.imwrite('train1_cropped.tif', np.array(img_list))\n",
    "\n",
    "# for k in range(mask.shape[0]):\n",
    "#     cropped_mask =cut_polygon_from_image(mask[k],corners, 37)\n",
    "#     mask_list.append(cropped_mask)\n",
    "\n",
    "# img_dict[i] = np.array(img_list)\n",
    "# mask_dict[i] = np.array(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiff.imshow(img_dict[0][89])\n",
    "i = 0 \n",
    "# img = np.array(img_dict[i])\n",
    "# mask = np.array(mask_dict[i])\n",
    "\n",
    "# cropped_imgs_dict = {}\n",
    "# cropped_masks_dict = {}\n",
    "# cropped_imgs = []\n",
    "# cropped_masks = []\n",
    "# for k in range(img.shape[0]):\n",
    "#     cropped_image = img[k][:, 1150:2950]\n",
    "#     cropped_imgs.append(cropped_image)\n",
    "# # tiff.imshow(np.array(cropped_imgs[89]))\n",
    "# for j in range(mask.shape[0]):\n",
    "#     cropped_masked = mask[j][:, 1150:2950]\n",
    "#     cropped_masks.append(cropped_masked)\n",
    " \n",
    "# img = np.array(cropped_imgs)\n",
    "pca_img = reduce_channels(img, n_components=30)\n",
    "cropped_imgs_dict[i] = pca_img\n",
    "# cropped_imgs_dict[i] = np.array(cropped_imgs)\n",
    "cropped_masks_dict[i] = np.array(cropped_masks)\n",
    "\n",
    "# tiff.imshow((cropped_imgs_dict[0][89]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3420, 1800)\n"
     ]
    }
   ],
   "source": [
    "print(cropped_imgs_dict[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiff.imshow(img_dict[1][89])\n",
    "# print(img_dict[0].shape)\n",
    "i = 0\n",
    "# img = np.array(img_dict[i])\n",
    "# mask = np.array(mask_dict[i])\n",
    "# cropped_imgs = []\n",
    "# cropped_masks = []\n",
    "# for k in range(img.shape[0]):\n",
    "#     cropped_image = img[k][:, 1350:3200]\n",
    "#     cropped_imgs.append(cropped_image)\n",
    "# tiff.imshow(np.array(cropped_imgs[89]))\n",
    "# for j in range(mask.shape[0]):\n",
    "#     cropped_masked = mask[j][:, 1350:3200]\n",
    "#     cropped_masks.append(cropped_masked)\n",
    "# tiff.imshow(np.array(cropped_masks[0]))   \n",
    "\n",
    "# img = np.array(cropped_imgs)\n",
    "pca_img = reduce_channels(img, n_components=30)\n",
    "# cropped_imgs_dict[i] = pca_img\n",
    "# cropped_masks_dict[i] = np.array(cropped_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3659, 1850)\n"
     ]
    }
   ],
   "source": [
    "print(cropped_imgs_dict[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiff.imshow(img_dict[2][89])\n",
    "# i = 2 \n",
    "# img = np.array(img_dict[i])\n",
    "# mask = np.array(mask_dict[i])\n",
    "# cropped_imgs = []\n",
    "# cropped_masks = []\n",
    "# for k in range(img.shape[0]):\n",
    "#     cropped_image = img[k][:, 1400:3100]\n",
    "#     cropped_imgs.append(cropped_image)\n",
    "# tiff.imshow(np.array(cropped_imgs[89]))\n",
    "# for j in range(mask.shape[0]):\n",
    "#     cropped_masked = mask[j][:, 1400:3100]\n",
    "#     cropped_masks.append(cropped_masked)\n",
    "# tiff.imshow(np.array(cropped_masks[0]))   \n",
    "\n",
    "# cropped_imgs_dict[i] = np.array(cropped_imgs)\n",
    "# cropped_masks_dict[i] = np.array(cropped_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiff.imshow(img_dict[3][89])\n",
    "# i = 3 \n",
    "# img = np.array(img_dict[i])\n",
    "# mask = np.array(mask_dict[i])\n",
    "# cropped_imgs = []\n",
    "# cropped_masks = []\n",
    "# for k in range(img.shape[0]):\n",
    "#     cropped_image = img[k][:, 1400:3100]\n",
    "#     cropped_imgs.append(cropped_image)\n",
    "# tiff.imshow(np.array(cropped_imgs[89]))\n",
    "# for j in range(mask.shape[0]):\n",
    "#     cropped_masked = mask[j][:, 1400:3100]\n",
    "#     cropped_masks.append(cropped_masked)\n",
    "# tiff.imshow(np.array(cropped_masks[0]))   \n",
    "\n",
    "# cropped_imgs_dict[i] = np.array(cropped_imgs)\n",
    "# cropped_masks_dict[i] = np.array(cropped_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3420, 1800)\n"
     ]
    }
   ],
   "source": [
    "print(cropped_masks_dict[0].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN = {}\n",
    "Y_TRAIN = {}\n",
    "X_VAL = {}\n",
    "Y_VAL = {}\n",
    "X_TEST = {}\n",
    "Y_TEST = {}\n",
    "\n",
    "# print(cropped_imgs_dict[i].shape)\n",
    "\n",
    "img = pca_img\n",
    "\n",
    "height = img.shape[1]\n",
    "width = img.shape[2]\n",
    "\n",
    "train_height = int(height*0.7)\n",
    "val_height = int(height*0.1)\n",
    "test_height = int(height* 0.2)\n",
    "\n",
    "#create dummy array for dividing the train, validate and test set\n",
    "train_img = np.zeros([img.shape[0], train_height, width])\n",
    "val_img = np.zeros([img.shape[0], val_height, width])\n",
    "test_img = np.zeros([img.shape[0], test_height, width])\n",
    "\n",
    "\n",
    "\n",
    "train_mask = np.zeros([img.shape[0], train_height, width])\n",
    "val_mask = np.zeros([img.shape[0], val_height, width])\n",
    "test_mask = np.zeros([img.shape[0], test_height, width])\n",
    "\n",
    "train_img = img[:, 0:train_height, 0:width]\n",
    "X_TRAIN[i] = train_img\n",
    "val_img = img[:, train_height:train_height+val_height, 0:width]\n",
    "X_VAL[i] = val_img\n",
    "test_img = img[:,train_height+val_height:height, 0:width]\n",
    "X_TEST[i] = test_img\n",
    "\n",
    "train_mask = mask[:, 0:train_height, 0:width]\n",
    "Y_TRAIN[i] = train_mask\n",
    "val_mask = mask[:, train_height:train_height+val_height, 0:width]\n",
    "Y_VAL[i] = val_mask\n",
    "test_mask = mask[:,train_height+val_height:height, 0:width]\n",
    "Y_TEST[i] = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1924, 1780)\n",
      "(3, 275, 1780)\n",
      "(3, 551, 1780)\n"
     ]
    }
   ],
   "source": [
    "print(Y_TRAIN[0].shape)\n",
    "print(Y_VAL[0].shape)\n",
    "print(Y_TEST[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "returns image normalized to be in [-1, 1]\n",
    "\"\"\"\n",
    "NB_BANDS      = 30\n",
    "NB_CLASSES    = 3   \n",
    "CLASS_WEIGHTS = [2, 1, 1]\n",
    "NB_EPOCHS     = 1000\n",
    "BATCH_SIZE    = 8\n",
    "UPCONV        = True\n",
    "PATCH_SIZE    = 224 # should be divisible by 16\n",
    "NB_TRAIN      = 800\n",
    "NB_VAL        = 200\n",
    "LEARNING_RATE =0.001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating patches\n",
      "Generated 72 patches\n",
      "Done generate train patches\n",
      "Generating patches\n",
      "Generated 16 patches\n",
      "Done generate validate patches\n",
      "Generating patches\n",
      "Generated 24 patches\n",
      "Done generate test patches\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = get_patches_not_random(X_TRAIN, Y_TRAIN, PATCH_SIZE, num_patches=400)\n",
    "print('Done generate train patches')\n",
    "x_val, y_val = get_patches_not_random(X_VAL, Y_VAL, PATCH_SIZE, num_patches=100)\n",
    "print('Done generate validate patches')\n",
    "x_test, y_test = get_patches_not_random(X_TEST, Y_TEST, PATCH_SIZE, num_patches=100)\n",
    "print('Done generate test patches')\n",
    "np.save('x_train.npy', x_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('x_val.npy', x_val)\n",
    "np.save('y_val.npy', y_val)\n",
    "np.save('x_test.npy', x_test)\n",
    "np.save('y_test.npy', y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_net(model, device,  x_train, y_train, x_val, y_val):\n",
    "    print(\"Training network\")\n",
    "    # x_train, y_train = get_patches(X_DICT_TRAIN, Y_DICT_TRAIN, NB_TRAIN, PATCH_SIZE)\n",
    "    \n",
    "    # x_val, y_val = get_patches(X_DICT_VAL, Y_DICT_VAL, NB_VAL, PATCH_SIZE)\n",
    "    # print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n",
    "    # y_train = np.where(y_train > 8, 255, 0)\n",
    "    # y_val = np.where(y_val > 5, 255, 0)\n",
    "    # u, c = np.unique(y_val, return_counts=True)\n",
    "    # dup = u[c > 1]\n",
    "    # print(dup)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    train_dat = torch.utils.data.TensorDataset(torch.cuda.FloatTensor(x_train), torch.cuda.FloatTensor(y_train))\n",
    "    train_loader = torch.utils.data.DataLoader(train_dat, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dat = torch.utils.data.TensorDataset(torch.cuda.FloatTensor(x_val), torch.cuda.FloatTensor(y_val))\n",
    "    val_loader = torch.utils.data.DataLoader(val_dat, batch_size=BATCH_SIZE, shuffle=False)  # No need to shuffle\n",
    "                \n",
    "     \n",
    "    # model = UNet(num_classes=3, in_channels=122, depth=6, merge_mode='concat').to(device)\n",
    "    # model = UNet(num_classes=3).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor(CLASS_WEIGHTS))\n",
    "    # criterion = nn.BCEWithLogitsLoss(pos_weight=torch.cuda.FloatTensor(CLASS_WEIGHTS))\n",
    "    # criterion = nn.BCELoss(weight=torch.cuda.FloatTensor(CLASS_WEIGHTS))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = NB_EPOCHS\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            # softmax = nn.Softmax(dim=1)\n",
    "            # targets = softmax(targets)\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += (loss.item() * inputs.size(0))\n",
    "            train_losses.append(train_loss)\n",
    "            #print(f'Training Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "                \n",
    "        # Validation phase\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Average losses\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss {val_loss:.4f}')\n",
    "        val_losses.append(val_loss)\n",
    "    torch.save(model.state_dict(), 'unet_model.pth')\n",
    "    print(\"Training done\")\n",
    "    return train_losses, val_losses, x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_415691/1895911190.py:15: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
      "  train_dat = torch.utils.data.TensorDataset(torch.cuda.FloatTensor(x_train), torch.cuda.FloatTensor(y_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Training Loss: 300.6138, Validation Loss 295.4893\n",
      "Epoch [2/1000], Training Loss: 286.8905, Validation Loss 273.1238\n",
      "Epoch [3/1000], Training Loss: 282.4315, Validation Loss 258.2150\n",
      "Epoch [4/1000], Training Loss: 280.0288, Validation Loss 249.6071\n",
      "Epoch [5/1000], Training Loss: 278.4540, Validation Loss 249.4802\n",
      "Epoch [6/1000], Training Loss: 278.1273, Validation Loss 249.3383\n",
      "Epoch [7/1000], Training Loss: 276.9488, Validation Loss 252.9566\n",
      "Epoch [8/1000], Training Loss: 276.3560, Validation Loss 258.0451\n",
      "Epoch [9/1000], Training Loss: 273.6879, Validation Loss 249.1575\n",
      "Epoch [10/1000], Training Loss: 272.2593, Validation Loss 238.5300\n",
      "Epoch [11/1000], Training Loss: 272.2591, Validation Loss 235.1357\n",
      "Epoch [12/1000], Training Loss: 270.9604, Validation Loss 230.4732\n",
      "Epoch [13/1000], Training Loss: 270.3853, Validation Loss 232.7578\n",
      "Epoch [14/1000], Training Loss: 269.5130, Validation Loss 236.3014\n",
      "Epoch [15/1000], Training Loss: 268.3335, Validation Loss 243.3201\n",
      "Epoch [16/1000], Training Loss: 268.0958, Validation Loss 240.8744\n",
      "Epoch [17/1000], Training Loss: 267.4959, Validation Loss 242.0234\n",
      "Epoch [18/1000], Training Loss: 268.1774, Validation Loss 245.3001\n",
      "Epoch [19/1000], Training Loss: 266.2346, Validation Loss 231.8687\n",
      "Epoch [20/1000], Training Loss: 266.7003, Validation Loss 224.0092\n",
      "Epoch [21/1000], Training Loss: 269.4381, Validation Loss 224.6548\n",
      "Epoch [22/1000], Training Loss: 270.9010, Validation Loss 228.8408\n",
      "Epoch [23/1000], Training Loss: 270.8669, Validation Loss 227.2922\n",
      "Epoch [24/1000], Training Loss: 270.5427, Validation Loss 227.1615\n",
      "Epoch [25/1000], Training Loss: 270.3376, Validation Loss 226.8108\n",
      "Epoch [26/1000], Training Loss: 270.1219, Validation Loss 227.6999\n",
      "Epoch [27/1000], Training Loss: 268.0872, Validation Loss 238.0159\n",
      "Epoch [28/1000], Training Loss: 272.7579, Validation Loss 231.9864\n",
      "Epoch [29/1000], Training Loss: 268.3456, Validation Loss 280.8021\n",
      "Epoch [30/1000], Training Loss: 266.1733, Validation Loss 253.1770\n",
      "Epoch [31/1000], Training Loss: 266.3409, Validation Loss 336.3466\n",
      "Epoch [32/1000], Training Loss: 267.9460, Validation Loss 253.7003\n",
      "Epoch [33/1000], Training Loss: 265.3919, Validation Loss 235.9647\n",
      "Epoch [34/1000], Training Loss: 265.1839, Validation Loss 234.7334\n",
      "Epoch [35/1000], Training Loss: 271.0228, Validation Loss 230.0309\n",
      "Epoch [36/1000], Training Loss: 267.5404, Validation Loss 234.6674\n",
      "Epoch [37/1000], Training Loss: 266.5765, Validation Loss 235.4401\n",
      "Epoch [38/1000], Training Loss: 266.5663, Validation Loss 237.1282\n",
      "Epoch [39/1000], Training Loss: 265.6884, Validation Loss 237.3802\n",
      "Epoch [40/1000], Training Loss: 269.2741, Validation Loss 235.2223\n",
      "Epoch [41/1000], Training Loss: 267.0215, Validation Loss 235.5802\n",
      "Epoch [42/1000], Training Loss: 265.7095, Validation Loss 236.6996\n",
      "Epoch [43/1000], Training Loss: 265.1444, Validation Loss 238.7964\n",
      "Epoch [44/1000], Training Loss: 265.0597, Validation Loss 242.6202\n",
      "Epoch [45/1000], Training Loss: 266.7861, Validation Loss 238.0434\n",
      "Epoch [46/1000], Training Loss: 264.5204, Validation Loss 245.7417\n",
      "Epoch [47/1000], Training Loss: 265.2883, Validation Loss 241.7413\n",
      "Epoch [48/1000], Training Loss: 265.2879, Validation Loss 249.8254\n",
      "Epoch [49/1000], Training Loss: 266.1740, Validation Loss 237.5109\n",
      "Epoch [50/1000], Training Loss: 267.2736, Validation Loss 233.5835\n",
      "Epoch [51/1000], Training Loss: 264.1590, Validation Loss 245.0173\n",
      "Epoch [52/1000], Training Loss: 265.4206, Validation Loss 240.4628\n",
      "Epoch [53/1000], Training Loss: 262.0160, Validation Loss 341.6516\n",
      "Epoch [54/1000], Training Loss: 274.4533, Validation Loss 249.7467\n",
      "Epoch [55/1000], Training Loss: 267.9860, Validation Loss 225.6930\n",
      "Epoch [56/1000], Training Loss: 264.7765, Validation Loss 235.6047\n",
      "Epoch [57/1000], Training Loss: 265.4471, Validation Loss 236.9986\n",
      "Epoch [58/1000], Training Loss: 266.2739, Validation Loss 240.5639\n",
      "Epoch [59/1000], Training Loss: 264.2326, Validation Loss 237.3223\n",
      "Epoch [60/1000], Training Loss: 263.6969, Validation Loss 233.9021\n",
      "Epoch [61/1000], Training Loss: 263.1080, Validation Loss 234.4890\n",
      "Epoch [62/1000], Training Loss: 263.9521, Validation Loss 239.1687\n",
      "Epoch [63/1000], Training Loss: 263.7413, Validation Loss 243.2408\n",
      "Epoch [64/1000], Training Loss: 264.6513, Validation Loss 237.5550\n",
      "Epoch [65/1000], Training Loss: 262.7629, Validation Loss 243.6829\n",
      "Epoch [66/1000], Training Loss: 262.9296, Validation Loss 245.1911\n",
      "Epoch [67/1000], Training Loss: 263.0737, Validation Loss 247.6680\n",
      "Epoch [68/1000], Training Loss: 264.5186, Validation Loss 241.2714\n",
      "Epoch [69/1000], Training Loss: 263.6381, Validation Loss 234.9393\n",
      "Epoch [70/1000], Training Loss: 264.5774, Validation Loss 229.7439\n",
      "Epoch [71/1000], Training Loss: 263.0708, Validation Loss 228.5205\n",
      "Epoch [72/1000], Training Loss: 260.6733, Validation Loss 229.7214\n",
      "Epoch [73/1000], Training Loss: 261.8469, Validation Loss 231.2591\n",
      "Epoch [74/1000], Training Loss: 263.0855, Validation Loss 230.2019\n",
      "Epoch [75/1000], Training Loss: 261.9738, Validation Loss 236.5308\n",
      "Epoch [76/1000], Training Loss: 261.8673, Validation Loss 232.5607\n",
      "Epoch [77/1000], Training Loss: 260.6606, Validation Loss 234.2562\n",
      "Epoch [78/1000], Training Loss: 260.4455, Validation Loss 236.7713\n",
      "Epoch [79/1000], Training Loss: 261.1947, Validation Loss 230.6989\n",
      "Epoch [80/1000], Training Loss: 261.7625, Validation Loss 232.2895\n",
      "Epoch [81/1000], Training Loss: 258.5228, Validation Loss 236.7111\n",
      "Epoch [82/1000], Training Loss: 259.2221, Validation Loss 236.1738\n",
      "Epoch [83/1000], Training Loss: 259.3996, Validation Loss 237.8804\n",
      "Epoch [84/1000], Training Loss: 257.3949, Validation Loss 238.0720\n",
      "Epoch [85/1000], Training Loss: 262.5713, Validation Loss 241.3536\n",
      "Epoch [86/1000], Training Loss: 260.0421, Validation Loss 240.4521\n",
      "Epoch [87/1000], Training Loss: 258.1356, Validation Loss 234.6376\n",
      "Epoch [88/1000], Training Loss: 259.1555, Validation Loss 229.4723\n",
      "Epoch [89/1000], Training Loss: 257.9904, Validation Loss 231.6230\n",
      "Epoch [90/1000], Training Loss: 257.2567, Validation Loss 232.6471\n",
      "Epoch [91/1000], Training Loss: 256.9773, Validation Loss 231.7652\n",
      "Epoch [92/1000], Training Loss: 256.5924, Validation Loss 233.9319\n",
      "Epoch [93/1000], Training Loss: 256.9021, Validation Loss 240.7272\n",
      "Epoch [94/1000], Training Loss: 258.3447, Validation Loss 249.8019\n",
      "Epoch [95/1000], Training Loss: 257.3282, Validation Loss 235.9412\n",
      "Epoch [96/1000], Training Loss: 259.3607, Validation Loss 232.8333\n",
      "Epoch [97/1000], Training Loss: 255.7904, Validation Loss 237.6225\n",
      "Epoch [98/1000], Training Loss: 254.2949, Validation Loss 233.7201\n",
      "Epoch [99/1000], Training Loss: 253.6245, Validation Loss 236.2830\n",
      "Epoch [100/1000], Training Loss: 253.2222, Validation Loss 254.5274\n",
      "Epoch [101/1000], Training Loss: 252.0308, Validation Loss 243.8881\n",
      "Epoch [102/1000], Training Loss: 253.4433, Validation Loss 230.4906\n",
      "Epoch [103/1000], Training Loss: 253.8713, Validation Loss 229.4719\n",
      "Epoch [104/1000], Training Loss: 251.0004, Validation Loss 247.6952\n",
      "Epoch [105/1000], Training Loss: 248.2502, Validation Loss 247.6424\n",
      "Epoch [106/1000], Training Loss: 244.9425, Validation Loss 230.8851\n",
      "Epoch [107/1000], Training Loss: 251.6989, Validation Loss 268.3653\n",
      "Epoch [108/1000], Training Loss: 244.6151, Validation Loss 275.1209\n",
      "Epoch [109/1000], Training Loss: 238.8543, Validation Loss 251.7521\n",
      "Epoch [110/1000], Training Loss: 243.7143, Validation Loss 264.8242\n",
      "Epoch [111/1000], Training Loss: 250.0558, Validation Loss 278.2848\n",
      "Epoch [112/1000], Training Loss: 257.1243, Validation Loss 267.2586\n",
      "Epoch [113/1000], Training Loss: 252.4834, Validation Loss 249.0167\n",
      "Epoch [114/1000], Training Loss: 251.5486, Validation Loss 237.5992\n",
      "Epoch [115/1000], Training Loss: 249.8176, Validation Loss 231.8304\n",
      "Epoch [116/1000], Training Loss: 239.7734, Validation Loss 252.6406\n",
      "Epoch [117/1000], Training Loss: 237.4632, Validation Loss 239.8980\n",
      "Epoch [118/1000], Training Loss: 231.9261, Validation Loss 247.0877\n",
      "Epoch [119/1000], Training Loss: 230.4692, Validation Loss 252.6355\n",
      "Epoch [120/1000], Training Loss: 235.4659, Validation Loss 248.2893\n",
      "Epoch [121/1000], Training Loss: 233.1460, Validation Loss 269.9624\n",
      "Epoch [122/1000], Training Loss: 231.0336, Validation Loss 255.0211\n",
      "Epoch [123/1000], Training Loss: 229.5016, Validation Loss 256.0927\n",
      "Epoch [124/1000], Training Loss: 231.2442, Validation Loss 263.6725\n",
      "Epoch [125/1000], Training Loss: 234.7026, Validation Loss 268.0799\n",
      "Epoch [126/1000], Training Loss: 227.6349, Validation Loss 277.3244\n",
      "Epoch [127/1000], Training Loss: 228.7314, Validation Loss 255.3694\n",
      "Epoch [128/1000], Training Loss: 227.3970, Validation Loss 252.3160\n",
      "Epoch [129/1000], Training Loss: 219.4320, Validation Loss 253.6157\n",
      "Epoch [130/1000], Training Loss: 231.5212, Validation Loss 250.9544\n",
      "Epoch [131/1000], Training Loss: 219.9245, Validation Loss 270.0390\n",
      "Epoch [132/1000], Training Loss: 226.2824, Validation Loss 268.9829\n",
      "Epoch [133/1000], Training Loss: 220.9438, Validation Loss 262.4646\n",
      "Epoch [134/1000], Training Loss: 215.1719, Validation Loss 249.4954\n",
      "Epoch [135/1000], Training Loss: 215.5803, Validation Loss 269.1642\n",
      "Epoch [136/1000], Training Loss: 222.6993, Validation Loss 278.6369\n",
      "Epoch [137/1000], Training Loss: 218.9531, Validation Loss 256.5327\n",
      "Epoch [138/1000], Training Loss: 215.5421, Validation Loss 279.8470\n",
      "Epoch [139/1000], Training Loss: 219.7216, Validation Loss 263.1490\n",
      "Epoch [140/1000], Training Loss: 218.9991, Validation Loss 246.3347\n",
      "Epoch [141/1000], Training Loss: 210.8379, Validation Loss 275.4480\n",
      "Epoch [142/1000], Training Loss: 217.0926, Validation Loss 256.5674\n",
      "Epoch [143/1000], Training Loss: 214.8857, Validation Loss 287.9555\n",
      "Epoch [144/1000], Training Loss: 215.1490, Validation Loss 259.3569\n",
      "Epoch [145/1000], Training Loss: 217.9801, Validation Loss 275.4856\n",
      "Epoch [146/1000], Training Loss: 215.9404, Validation Loss 274.6506\n",
      "Epoch [147/1000], Training Loss: 218.5763, Validation Loss 256.6747\n",
      "Epoch [148/1000], Training Loss: 215.4675, Validation Loss 263.2065\n",
      "Epoch [149/1000], Training Loss: 213.2486, Validation Loss 280.3799\n",
      "Epoch [150/1000], Training Loss: 214.6156, Validation Loss 288.5512\n",
      "Epoch [151/1000], Training Loss: 209.7221, Validation Loss 287.2516\n",
      "Epoch [152/1000], Training Loss: 212.3814, Validation Loss 278.1136\n",
      "Epoch [153/1000], Training Loss: 214.1085, Validation Loss 270.6821\n",
      "Epoch [154/1000], Training Loss: 208.5036, Validation Loss 257.2015\n",
      "Epoch [155/1000], Training Loss: 211.5282, Validation Loss 278.5703\n",
      "Epoch [156/1000], Training Loss: 210.5355, Validation Loss 272.8644\n",
      "Epoch [157/1000], Training Loss: 212.0665, Validation Loss 278.9737\n",
      "Epoch [158/1000], Training Loss: 213.2851, Validation Loss 266.6528\n",
      "Epoch [159/1000], Training Loss: 211.6079, Validation Loss 273.1978\n",
      "Epoch [160/1000], Training Loss: 206.5489, Validation Loss 275.6533\n",
      "Epoch [161/1000], Training Loss: 209.1750, Validation Loss 274.0846\n",
      "Epoch [162/1000], Training Loss: 207.3950, Validation Loss 270.2282\n",
      "Epoch [163/1000], Training Loss: 212.2431, Validation Loss 300.2681\n",
      "Epoch [164/1000], Training Loss: 209.4406, Validation Loss 309.8211\n",
      "Epoch [165/1000], Training Loss: 219.4650, Validation Loss 265.8805\n",
      "Epoch [166/1000], Training Loss: 206.9912, Validation Loss 269.2430\n",
      "Epoch [167/1000], Training Loss: 210.9726, Validation Loss 298.4471\n",
      "Epoch [168/1000], Training Loss: 207.1296, Validation Loss 302.1718\n",
      "Epoch [169/1000], Training Loss: 204.4756, Validation Loss 279.7511\n",
      "Epoch [170/1000], Training Loss: 204.7788, Validation Loss 287.9029\n",
      "Epoch [171/1000], Training Loss: 210.1766, Validation Loss 318.8249\n",
      "Epoch [172/1000], Training Loss: 213.7712, Validation Loss 298.4731\n",
      "Epoch [173/1000], Training Loss: 202.4321, Validation Loss 282.7054\n",
      "Epoch [174/1000], Training Loss: 200.8320, Validation Loss 300.4640\n",
      "Epoch [175/1000], Training Loss: 206.6849, Validation Loss 316.8248\n",
      "Epoch [176/1000], Training Loss: 208.2558, Validation Loss 300.0834\n",
      "Epoch [177/1000], Training Loss: 201.8186, Validation Loss 306.6880\n",
      "Epoch [178/1000], Training Loss: 206.2028, Validation Loss 289.6859\n",
      "Epoch [179/1000], Training Loss: 208.3245, Validation Loss 302.3197\n",
      "Epoch [180/1000], Training Loss: 203.1135, Validation Loss 299.7181\n",
      "Epoch [181/1000], Training Loss: 200.6322, Validation Loss 298.1863\n",
      "Epoch [182/1000], Training Loss: 201.7613, Validation Loss 304.6483\n",
      "Epoch [183/1000], Training Loss: 197.9533, Validation Loss 318.1351\n",
      "Epoch [184/1000], Training Loss: 199.6604, Validation Loss 280.6656\n",
      "Epoch [185/1000], Training Loss: 200.3544, Validation Loss 309.4886\n",
      "Epoch [186/1000], Training Loss: 200.0084, Validation Loss 312.6614\n",
      "Epoch [187/1000], Training Loss: 196.2643, Validation Loss 325.5544\n",
      "Epoch [188/1000], Training Loss: 204.4403, Validation Loss 324.9230\n",
      "Epoch [189/1000], Training Loss: 200.4722, Validation Loss 295.4651\n",
      "Epoch [190/1000], Training Loss: 201.2940, Validation Loss 301.5181\n",
      "Epoch [191/1000], Training Loss: 197.1942, Validation Loss 316.0541\n",
      "Epoch [192/1000], Training Loss: 198.1999, Validation Loss 311.6286\n",
      "Epoch [193/1000], Training Loss: 198.1506, Validation Loss 301.9009\n",
      "Epoch [194/1000], Training Loss: 197.3497, Validation Loss 293.6592\n",
      "Epoch [195/1000], Training Loss: 190.1966, Validation Loss 306.6405\n",
      "Epoch [196/1000], Training Loss: 190.1343, Validation Loss 302.1889\n",
      "Epoch [197/1000], Training Loss: 191.8577, Validation Loss 297.4729\n",
      "Epoch [198/1000], Training Loss: 198.0206, Validation Loss 345.4215\n",
      "Epoch [199/1000], Training Loss: 193.4058, Validation Loss 311.1867\n",
      "Epoch [200/1000], Training Loss: 192.3765, Validation Loss 306.7981\n",
      "Epoch [201/1000], Training Loss: 194.5092, Validation Loss 315.6226\n",
      "Epoch [202/1000], Training Loss: 195.2621, Validation Loss 325.5072\n",
      "Epoch [203/1000], Training Loss: 188.3650, Validation Loss 296.2348\n",
      "Epoch [204/1000], Training Loss: 189.7923, Validation Loss 297.0247\n",
      "Epoch [205/1000], Training Loss: 190.9847, Validation Loss 306.6594\n",
      "Epoch [206/1000], Training Loss: 189.5809, Validation Loss 309.2803\n",
      "Epoch [207/1000], Training Loss: 186.7679, Validation Loss 314.9017\n",
      "Epoch [208/1000], Training Loss: 183.2145, Validation Loss 318.1143\n",
      "Epoch [209/1000], Training Loss: 181.9632, Validation Loss 300.8004\n",
      "Epoch [210/1000], Training Loss: 187.4840, Validation Loss 308.2713\n",
      "Epoch [211/1000], Training Loss: 187.7616, Validation Loss 309.8141\n",
      "Epoch [212/1000], Training Loss: 182.5640, Validation Loss 307.5338\n",
      "Epoch [213/1000], Training Loss: 183.3205, Validation Loss 318.4453\n",
      "Epoch [214/1000], Training Loss: 179.7615, Validation Loss 310.1423\n",
      "Epoch [215/1000], Training Loss: 181.5778, Validation Loss 313.3480\n",
      "Epoch [216/1000], Training Loss: 184.9263, Validation Loss 314.4975\n",
      "Epoch [217/1000], Training Loss: 181.0706, Validation Loss 318.7827\n",
      "Epoch [218/1000], Training Loss: 180.0202, Validation Loss 328.0012\n",
      "Epoch [219/1000], Training Loss: 178.7319, Validation Loss 322.0135\n",
      "Epoch [220/1000], Training Loss: 183.8661, Validation Loss 318.9322\n",
      "Epoch [221/1000], Training Loss: 185.8782, Validation Loss 304.2404\n",
      "Epoch [222/1000], Training Loss: 183.4442, Validation Loss 307.8397\n",
      "Epoch [223/1000], Training Loss: 180.6888, Validation Loss 308.6306\n",
      "Epoch [224/1000], Training Loss: 181.7026, Validation Loss 313.3371\n",
      "Epoch [225/1000], Training Loss: 178.1900, Validation Loss 313.6990\n",
      "Epoch [226/1000], Training Loss: 176.5376, Validation Loss 309.9065\n",
      "Epoch [227/1000], Training Loss: 174.8653, Validation Loss 310.9041\n",
      "Epoch [228/1000], Training Loss: 175.3728, Validation Loss 317.0279\n",
      "Epoch [229/1000], Training Loss: 173.4931, Validation Loss 314.3627\n",
      "Epoch [230/1000], Training Loss: 176.1836, Validation Loss 330.0446\n",
      "Epoch [231/1000], Training Loss: 174.6511, Validation Loss 320.5459\n",
      "Epoch [232/1000], Training Loss: 177.8723, Validation Loss 326.5405\n",
      "Epoch [233/1000], Training Loss: 174.0749, Validation Loss 323.4150\n",
      "Epoch [234/1000], Training Loss: 178.0150, Validation Loss 297.7365\n",
      "Epoch [235/1000], Training Loss: 180.2927, Validation Loss 317.8766\n",
      "Epoch [236/1000], Training Loss: 181.2338, Validation Loss 307.7545\n",
      "Epoch [237/1000], Training Loss: 176.8216, Validation Loss 323.9160\n",
      "Epoch [238/1000], Training Loss: 177.2047, Validation Loss 323.1559\n",
      "Epoch [239/1000], Training Loss: 173.1281, Validation Loss 325.1467\n",
      "Epoch [240/1000], Training Loss: 174.4079, Validation Loss 309.3249\n",
      "Epoch [241/1000], Training Loss: 173.5108, Validation Loss 304.3067\n",
      "Epoch [242/1000], Training Loss: 174.8162, Validation Loss 320.9778\n",
      "Epoch [243/1000], Training Loss: 174.0535, Validation Loss 312.1655\n",
      "Epoch [244/1000], Training Loss: 175.7673, Validation Loss 309.8122\n",
      "Epoch [245/1000], Training Loss: 177.7728, Validation Loss 348.2980\n",
      "Epoch [246/1000], Training Loss: 172.6902, Validation Loss 340.4908\n",
      "Epoch [247/1000], Training Loss: 172.0359, Validation Loss 338.2612\n",
      "Epoch [248/1000], Training Loss: 171.7608, Validation Loss 327.8731\n",
      "Epoch [249/1000], Training Loss: 175.2930, Validation Loss 328.8427\n",
      "Epoch [250/1000], Training Loss: 170.8082, Validation Loss 310.6001\n",
      "Epoch [251/1000], Training Loss: 171.9115, Validation Loss 324.2692\n",
      "Epoch [252/1000], Training Loss: 167.9480, Validation Loss 341.8895\n",
      "Epoch [253/1000], Training Loss: 173.9234, Validation Loss 325.6556\n",
      "Epoch [254/1000], Training Loss: 170.0260, Validation Loss 317.7474\n",
      "Epoch [255/1000], Training Loss: 171.0480, Validation Loss 315.2445\n",
      "Epoch [256/1000], Training Loss: 169.3038, Validation Loss 335.3741\n",
      "Epoch [257/1000], Training Loss: 172.1104, Validation Loss 338.3684\n",
      "Epoch [258/1000], Training Loss: 167.0619, Validation Loss 340.7093\n",
      "Epoch [259/1000], Training Loss: 167.3140, Validation Loss 337.3622\n",
      "Epoch [260/1000], Training Loss: 166.8948, Validation Loss 339.3216\n",
      "Epoch [261/1000], Training Loss: 167.7081, Validation Loss 327.5862\n",
      "Epoch [262/1000], Training Loss: 166.8474, Validation Loss 342.7058\n",
      "Epoch [263/1000], Training Loss: 165.8585, Validation Loss 346.7016\n",
      "Epoch [264/1000], Training Loss: 167.7404, Validation Loss 354.4441\n",
      "Epoch [265/1000], Training Loss: 167.3087, Validation Loss 343.2978\n",
      "Epoch [266/1000], Training Loss: 167.3429, Validation Loss 345.9022\n",
      "Epoch [267/1000], Training Loss: 169.1259, Validation Loss 350.2124\n",
      "Epoch [268/1000], Training Loss: 166.8001, Validation Loss 334.7290\n",
      "Epoch [269/1000], Training Loss: 165.3625, Validation Loss 334.8552\n",
      "Epoch [270/1000], Training Loss: 165.5382, Validation Loss 340.4971\n",
      "Epoch [271/1000], Training Loss: 165.3953, Validation Loss 340.9541\n",
      "Epoch [272/1000], Training Loss: 164.4714, Validation Loss 346.5885\n",
      "Epoch [273/1000], Training Loss: 164.6847, Validation Loss 337.4573\n",
      "Epoch [274/1000], Training Loss: 163.7018, Validation Loss 336.7376\n",
      "Epoch [275/1000], Training Loss: 164.5742, Validation Loss 343.1277\n",
      "Epoch [276/1000], Training Loss: 163.5053, Validation Loss 344.0945\n",
      "Epoch [277/1000], Training Loss: 164.3512, Validation Loss 336.8537\n",
      "Epoch [278/1000], Training Loss: 164.5573, Validation Loss 337.6878\n",
      "Epoch [279/1000], Training Loss: 163.2384, Validation Loss 344.9592\n",
      "Epoch [280/1000], Training Loss: 163.6245, Validation Loss 345.8535\n",
      "Epoch [281/1000], Training Loss: 163.4891, Validation Loss 343.0813\n",
      "Epoch [282/1000], Training Loss: 163.0389, Validation Loss 354.0585\n",
      "Epoch [283/1000], Training Loss: 163.4118, Validation Loss 340.9071\n",
      "Epoch [284/1000], Training Loss: 162.8512, Validation Loss 334.1563\n",
      "Epoch [285/1000], Training Loss: 163.3949, Validation Loss 345.0600\n",
      "Epoch [286/1000], Training Loss: 162.8935, Validation Loss 345.0993\n",
      "Epoch [287/1000], Training Loss: 163.3715, Validation Loss 342.3311\n",
      "Epoch [288/1000], Training Loss: 163.7706, Validation Loss 348.3017\n",
      "Epoch [289/1000], Training Loss: 163.1936, Validation Loss 348.5168\n",
      "Epoch [290/1000], Training Loss: 163.7562, Validation Loss 344.2292\n",
      "Epoch [291/1000], Training Loss: 163.8950, Validation Loss 336.7592\n",
      "Epoch [292/1000], Training Loss: 164.4172, Validation Loss 347.1884\n",
      "Epoch [293/1000], Training Loss: 163.1372, Validation Loss 343.3911\n",
      "Epoch [294/1000], Training Loss: 162.8220, Validation Loss 335.8665\n",
      "Epoch [295/1000], Training Loss: 163.2880, Validation Loss 355.0203\n",
      "Epoch [296/1000], Training Loss: 163.0333, Validation Loss 346.6455\n",
      "Epoch [297/1000], Training Loss: 162.7788, Validation Loss 347.9520\n",
      "Epoch [298/1000], Training Loss: 165.9055, Validation Loss 351.7047\n",
      "Epoch [299/1000], Training Loss: 164.7283, Validation Loss 349.4481\n",
      "Epoch [300/1000], Training Loss: 164.5656, Validation Loss 326.2193\n",
      "Epoch [301/1000], Training Loss: 166.9672, Validation Loss 344.8662\n",
      "Epoch [302/1000], Training Loss: 164.0333, Validation Loss 339.1559\n",
      "Epoch [303/1000], Training Loss: 163.9227, Validation Loss 352.4598\n",
      "Epoch [304/1000], Training Loss: 164.6805, Validation Loss 353.0428\n",
      "Epoch [305/1000], Training Loss: 167.6891, Validation Loss 358.1813\n",
      "Epoch [306/1000], Training Loss: 163.9417, Validation Loss 359.5173\n",
      "Epoch [307/1000], Training Loss: 167.8050, Validation Loss 334.7601\n",
      "Epoch [308/1000], Training Loss: 168.6210, Validation Loss 328.7657\n",
      "Epoch [309/1000], Training Loss: 169.9357, Validation Loss 320.9167\n",
      "Epoch [310/1000], Training Loss: 168.6356, Validation Loss 340.2612\n",
      "Epoch [311/1000], Training Loss: 163.6299, Validation Loss 335.2133\n",
      "Epoch [312/1000], Training Loss: 165.3260, Validation Loss 321.1624\n",
      "Epoch [313/1000], Training Loss: 162.8955, Validation Loss 324.1740\n",
      "Epoch [314/1000], Training Loss: 163.6816, Validation Loss 342.3460\n",
      "Epoch [315/1000], Training Loss: 162.4800, Validation Loss 335.2122\n",
      "Epoch [316/1000], Training Loss: 161.2345, Validation Loss 345.0361\n",
      "Epoch [317/1000], Training Loss: 161.3606, Validation Loss 352.7137\n",
      "Epoch [318/1000], Training Loss: 161.2597, Validation Loss 337.3168\n",
      "Epoch [319/1000], Training Loss: 161.7500, Validation Loss 341.5350\n",
      "Epoch [320/1000], Training Loss: 160.5654, Validation Loss 347.1246\n",
      "Epoch [321/1000], Training Loss: 160.9017, Validation Loss 345.1540\n",
      "Epoch [322/1000], Training Loss: 160.9933, Validation Loss 347.2656\n",
      "Epoch [323/1000], Training Loss: 160.3905, Validation Loss 347.6170\n",
      "Epoch [324/1000], Training Loss: 160.2372, Validation Loss 350.2886\n",
      "Epoch [325/1000], Training Loss: 159.9446, Validation Loss 345.7634\n",
      "Epoch [326/1000], Training Loss: 161.6922, Validation Loss 358.5635\n",
      "Epoch [327/1000], Training Loss: 162.5039, Validation Loss 351.1120\n",
      "Epoch [328/1000], Training Loss: 162.8393, Validation Loss 346.9139\n",
      "Epoch [329/1000], Training Loss: 160.6296, Validation Loss 356.1655\n",
      "Epoch [330/1000], Training Loss: 160.3779, Validation Loss 356.0787\n",
      "Epoch [331/1000], Training Loss: 160.2078, Validation Loss 344.0744\n",
      "Epoch [332/1000], Training Loss: 159.8139, Validation Loss 341.8556\n",
      "Epoch [333/1000], Training Loss: 159.8842, Validation Loss 338.3442\n",
      "Epoch [334/1000], Training Loss: 159.4883, Validation Loss 344.6366\n",
      "Epoch [335/1000], Training Loss: 159.3771, Validation Loss 350.5602\n",
      "Epoch [336/1000], Training Loss: 160.1525, Validation Loss 354.7823\n",
      "Epoch [337/1000], Training Loss: 159.5129, Validation Loss 348.6916\n",
      "Epoch [338/1000], Training Loss: 159.3609, Validation Loss 345.6473\n",
      "Epoch [339/1000], Training Loss: 159.3591, Validation Loss 340.8401\n",
      "Epoch [340/1000], Training Loss: 159.4555, Validation Loss 343.3752\n",
      "Epoch [341/1000], Training Loss: 159.5583, Validation Loss 350.0525\n",
      "Epoch [342/1000], Training Loss: 159.1953, Validation Loss 358.9998\n",
      "Epoch [343/1000], Training Loss: 159.3708, Validation Loss 341.5421\n",
      "Epoch [344/1000], Training Loss: 159.7469, Validation Loss 341.6857\n",
      "Epoch [345/1000], Training Loss: 159.1238, Validation Loss 351.5820\n",
      "Epoch [346/1000], Training Loss: 159.1261, Validation Loss 359.7932\n",
      "Epoch [347/1000], Training Loss: 159.3115, Validation Loss 355.8571\n",
      "Epoch [348/1000], Training Loss: 158.9745, Validation Loss 355.5295\n",
      "Epoch [349/1000], Training Loss: 159.4359, Validation Loss 350.6221\n",
      "Epoch [350/1000], Training Loss: 159.7524, Validation Loss 356.9727\n",
      "Epoch [351/1000], Training Loss: 159.6487, Validation Loss 350.7635\n",
      "Epoch [352/1000], Training Loss: 159.4691, Validation Loss 354.1867\n",
      "Epoch [353/1000], Training Loss: 158.9676, Validation Loss 357.9182\n",
      "Epoch [354/1000], Training Loss: 158.8090, Validation Loss 356.0666\n",
      "Epoch [355/1000], Training Loss: 158.8319, Validation Loss 349.2626\n",
      "Epoch [356/1000], Training Loss: 159.0712, Validation Loss 357.5106\n",
      "Epoch [357/1000], Training Loss: 158.7458, Validation Loss 364.8910\n",
      "Epoch [358/1000], Training Loss: 159.0184, Validation Loss 359.4026\n",
      "Epoch [359/1000], Training Loss: 158.8152, Validation Loss 356.3888\n",
      "Epoch [360/1000], Training Loss: 158.8982, Validation Loss 355.8797\n",
      "Epoch [361/1000], Training Loss: 158.8705, Validation Loss 356.4718\n",
      "Epoch [362/1000], Training Loss: 158.6958, Validation Loss 352.9729\n",
      "Epoch [363/1000], Training Loss: 159.1078, Validation Loss 353.0441\n",
      "Epoch [364/1000], Training Loss: 159.1013, Validation Loss 358.3004\n",
      "Epoch [365/1000], Training Loss: 159.0786, Validation Loss 353.9218\n",
      "Epoch [366/1000], Training Loss: 158.6542, Validation Loss 350.0856\n",
      "Epoch [367/1000], Training Loss: 158.8537, Validation Loss 344.0074\n",
      "Epoch [368/1000], Training Loss: 158.7051, Validation Loss 345.7966\n",
      "Epoch [369/1000], Training Loss: 158.8695, Validation Loss 345.0645\n",
      "Epoch [370/1000], Training Loss: 158.7336, Validation Loss 346.7342\n",
      "Epoch [371/1000], Training Loss: 158.6018, Validation Loss 348.3490\n",
      "Epoch [372/1000], Training Loss: 158.5137, Validation Loss 349.6206\n",
      "Epoch [373/1000], Training Loss: 158.5409, Validation Loss 347.2481\n",
      "Epoch [374/1000], Training Loss: 158.5667, Validation Loss 348.2390\n",
      "Epoch [375/1000], Training Loss: 158.6395, Validation Loss 348.4426\n",
      "Epoch [376/1000], Training Loss: 158.5574, Validation Loss 350.5969\n",
      "Epoch [377/1000], Training Loss: 158.4542, Validation Loss 354.4258\n",
      "Epoch [378/1000], Training Loss: 158.5613, Validation Loss 353.0692\n",
      "Epoch [379/1000], Training Loss: 158.6385, Validation Loss 343.9538\n",
      "Epoch [380/1000], Training Loss: 158.6120, Validation Loss 346.5414\n",
      "Epoch [381/1000], Training Loss: 158.6159, Validation Loss 351.1893\n",
      "Epoch [382/1000], Training Loss: 158.4533, Validation Loss 354.6854\n",
      "Epoch [383/1000], Training Loss: 158.5648, Validation Loss 350.1492\n",
      "Epoch [384/1000], Training Loss: 160.1716, Validation Loss 341.3230\n",
      "Epoch [385/1000], Training Loss: 159.1564, Validation Loss 364.7030\n",
      "Epoch [386/1000], Training Loss: 159.2582, Validation Loss 358.0517\n",
      "Epoch [387/1000], Training Loss: 158.8915, Validation Loss 354.6606\n",
      "Epoch [388/1000], Training Loss: 158.8985, Validation Loss 364.8938\n",
      "Epoch [389/1000], Training Loss: 158.9342, Validation Loss 353.3182\n",
      "Epoch [390/1000], Training Loss: 158.6482, Validation Loss 347.3881\n",
      "Epoch [391/1000], Training Loss: 158.3952, Validation Loss 347.5968\n",
      "Epoch [392/1000], Training Loss: 158.4137, Validation Loss 349.6176\n",
      "Epoch [393/1000], Training Loss: 158.5192, Validation Loss 352.4717\n",
      "Epoch [394/1000], Training Loss: 158.4071, Validation Loss 351.2084\n",
      "Epoch [395/1000], Training Loss: 158.5406, Validation Loss 346.6716\n",
      "Epoch [396/1000], Training Loss: 158.4524, Validation Loss 355.1608\n",
      "Epoch [397/1000], Training Loss: 158.6001, Validation Loss 353.5332\n",
      "Epoch [398/1000], Training Loss: 158.4494, Validation Loss 350.2242\n",
      "Epoch [399/1000], Training Loss: 158.4747, Validation Loss 354.9532\n",
      "Epoch [400/1000], Training Loss: 158.7924, Validation Loss 356.2166\n",
      "Epoch [401/1000], Training Loss: 158.8351, Validation Loss 354.6637\n",
      "Epoch [402/1000], Training Loss: 162.3858, Validation Loss 357.1597\n",
      "Epoch [403/1000], Training Loss: 163.3228, Validation Loss 337.3952\n",
      "Epoch [404/1000], Training Loss: 164.8613, Validation Loss 347.8080\n",
      "Epoch [405/1000], Training Loss: 168.3927, Validation Loss 340.4785\n",
      "Epoch [406/1000], Training Loss: 166.3052, Validation Loss 338.3454\n",
      "Epoch [407/1000], Training Loss: 169.3862, Validation Loss 366.3623\n",
      "Epoch [408/1000], Training Loss: 168.5982, Validation Loss 342.9295\n",
      "Epoch [409/1000], Training Loss: 168.5288, Validation Loss 345.0468\n",
      "Epoch [410/1000], Training Loss: 165.4531, Validation Loss 334.5895\n",
      "Epoch [411/1000], Training Loss: 167.4821, Validation Loss 324.1613\n",
      "Epoch [412/1000], Training Loss: 168.2887, Validation Loss 352.6978\n",
      "Epoch [413/1000], Training Loss: 169.2560, Validation Loss 342.3581\n",
      "Epoch [414/1000], Training Loss: 167.2788, Validation Loss 357.5838\n",
      "Epoch [415/1000], Training Loss: 167.0503, Validation Loss 332.3808\n",
      "Epoch [416/1000], Training Loss: 164.4086, Validation Loss 341.7597\n",
      "Epoch [417/1000], Training Loss: 163.3549, Validation Loss 344.6302\n",
      "Epoch [418/1000], Training Loss: 162.8726, Validation Loss 335.7293\n",
      "Epoch [419/1000], Training Loss: 162.0719, Validation Loss 335.3589\n",
      "Epoch [420/1000], Training Loss: 161.8747, Validation Loss 339.0597\n",
      "Epoch [421/1000], Training Loss: 160.2395, Validation Loss 352.3924\n",
      "Epoch [422/1000], Training Loss: 159.4573, Validation Loss 372.1296\n",
      "Epoch [423/1000], Training Loss: 158.9596, Validation Loss 367.9817\n",
      "Epoch [424/1000], Training Loss: 159.4589, Validation Loss 367.4712\n",
      "Epoch [425/1000], Training Loss: 159.3695, Validation Loss 349.0763\n",
      "Epoch [426/1000], Training Loss: 159.2214, Validation Loss 354.0636\n",
      "Epoch [427/1000], Training Loss: 158.8974, Validation Loss 349.2256\n",
      "Epoch [428/1000], Training Loss: 158.9372, Validation Loss 346.7722\n",
      "Epoch [429/1000], Training Loss: 158.7129, Validation Loss 344.4073\n",
      "Epoch [430/1000], Training Loss: 158.7308, Validation Loss 347.7207\n",
      "Epoch [431/1000], Training Loss: 159.4318, Validation Loss 349.7756\n",
      "Epoch [432/1000], Training Loss: 158.9457, Validation Loss 345.7847\n",
      "Epoch [433/1000], Training Loss: 158.8758, Validation Loss 346.4528\n",
      "Epoch [434/1000], Training Loss: 158.8949, Validation Loss 350.7525\n",
      "Epoch [435/1000], Training Loss: 158.7193, Validation Loss 357.3641\n",
      "Epoch [436/1000], Training Loss: 158.5610, Validation Loss 352.1420\n",
      "Epoch [437/1000], Training Loss: 158.7406, Validation Loss 347.5254\n",
      "Epoch [438/1000], Training Loss: 158.3846, Validation Loss 345.3571\n",
      "Epoch [439/1000], Training Loss: 158.4125, Validation Loss 348.8526\n",
      "Epoch [440/1000], Training Loss: 158.3464, Validation Loss 351.3446\n",
      "Epoch [441/1000], Training Loss: 159.7113, Validation Loss 347.1291\n",
      "Epoch [442/1000], Training Loss: 160.3585, Validation Loss 345.0685\n",
      "Epoch [443/1000], Training Loss: 159.6410, Validation Loss 354.4240\n",
      "Epoch [444/1000], Training Loss: 159.2617, Validation Loss 362.2229\n",
      "Epoch [445/1000], Training Loss: 159.1250, Validation Loss 360.5103\n",
      "Epoch [446/1000], Training Loss: 158.6538, Validation Loss 345.0417\n",
      "Epoch [447/1000], Training Loss: 158.6596, Validation Loss 349.6772\n",
      "Epoch [448/1000], Training Loss: 158.5662, Validation Loss 362.5849\n",
      "Epoch [449/1000], Training Loss: 158.7850, Validation Loss 366.2768\n",
      "Epoch [450/1000], Training Loss: 158.4934, Validation Loss 349.2252\n",
      "Epoch [451/1000], Training Loss: 158.3953, Validation Loss 348.0547\n",
      "Epoch [452/1000], Training Loss: 158.5581, Validation Loss 349.7034\n",
      "Epoch [453/1000], Training Loss: 158.3962, Validation Loss 352.7014\n",
      "Epoch [454/1000], Training Loss: 158.4762, Validation Loss 351.1849\n",
      "Epoch [455/1000], Training Loss: 158.4112, Validation Loss 354.0856\n",
      "Epoch [456/1000], Training Loss: 158.3945, Validation Loss 355.8340\n",
      "Epoch [457/1000], Training Loss: 158.2809, Validation Loss 355.3320\n",
      "Epoch [458/1000], Training Loss: 158.2896, Validation Loss 355.8892\n",
      "Epoch [459/1000], Training Loss: 158.2452, Validation Loss 356.1628\n",
      "Epoch [460/1000], Training Loss: 158.2584, Validation Loss 356.3690\n",
      "Epoch [461/1000], Training Loss: 158.3299, Validation Loss 355.9902\n",
      "Epoch [462/1000], Training Loss: 158.2863, Validation Loss 355.1636\n",
      "Epoch [463/1000], Training Loss: 158.2392, Validation Loss 352.7321\n",
      "Epoch [464/1000], Training Loss: 158.4265, Validation Loss 352.4537\n",
      "Epoch [465/1000], Training Loss: 158.3170, Validation Loss 354.0067\n",
      "Epoch [466/1000], Training Loss: 158.3033, Validation Loss 354.6128\n",
      "Epoch [467/1000], Training Loss: 158.2276, Validation Loss 352.5412\n",
      "Epoch [468/1000], Training Loss: 158.2589, Validation Loss 350.5926\n",
      "Epoch [469/1000], Training Loss: 158.3366, Validation Loss 351.9141\n",
      "Epoch [470/1000], Training Loss: 158.2217, Validation Loss 352.2979\n",
      "Epoch [471/1000], Training Loss: 158.2130, Validation Loss 352.6537\n",
      "Epoch [472/1000], Training Loss: 158.2359, Validation Loss 353.8494\n",
      "Epoch [473/1000], Training Loss: 158.2465, Validation Loss 353.2650\n",
      "Epoch [474/1000], Training Loss: 158.1899, Validation Loss 354.3408\n",
      "Epoch [475/1000], Training Loss: 158.2157, Validation Loss 355.9079\n",
      "Epoch [476/1000], Training Loss: 158.2248, Validation Loss 357.4461\n",
      "Epoch [477/1000], Training Loss: 160.1642, Validation Loss 352.5431\n",
      "Epoch [478/1000], Training Loss: 159.8081, Validation Loss 337.0682\n",
      "Epoch [479/1000], Training Loss: 160.2667, Validation Loss 337.7516\n",
      "Epoch [480/1000], Training Loss: 160.9709, Validation Loss 348.6064\n",
      "Epoch [481/1000], Training Loss: 159.9843, Validation Loss 346.9456\n",
      "Epoch [482/1000], Training Loss: 160.7101, Validation Loss 339.8835\n",
      "Epoch [483/1000], Training Loss: 161.1804, Validation Loss 330.0731\n",
      "Epoch [484/1000], Training Loss: 160.0791, Validation Loss 337.3561\n",
      "Epoch [485/1000], Training Loss: 159.7615, Validation Loss 337.1557\n",
      "Epoch [486/1000], Training Loss: 159.0334, Validation Loss 339.7793\n",
      "Epoch [487/1000], Training Loss: 170.4963, Validation Loss 393.7637\n",
      "Epoch [488/1000], Training Loss: 196.9340, Validation Loss 298.7903\n",
      "Epoch [489/1000], Training Loss: 177.2535, Validation Loss 351.0383\n",
      "Epoch [490/1000], Training Loss: 170.5288, Validation Loss 339.7371\n",
      "Epoch [491/1000], Training Loss: 165.5216, Validation Loss 354.1907\n",
      "Epoch [492/1000], Training Loss: 164.8875, Validation Loss 339.3753\n",
      "Epoch [493/1000], Training Loss: 161.5852, Validation Loss 352.2002\n",
      "Epoch [494/1000], Training Loss: 160.4962, Validation Loss 358.9437\n",
      "Epoch [495/1000], Training Loss: 163.0110, Validation Loss 376.0688\n",
      "Epoch [496/1000], Training Loss: 165.4316, Validation Loss 344.6665\n",
      "Epoch [497/1000], Training Loss: 162.2118, Validation Loss 337.8832\n",
      "Epoch [498/1000], Training Loss: 160.7411, Validation Loss 338.1256\n",
      "Epoch [499/1000], Training Loss: 160.6838, Validation Loss 333.7704\n",
      "Epoch [500/1000], Training Loss: 159.0146, Validation Loss 345.4251\n",
      "Epoch [501/1000], Training Loss: 159.1107, Validation Loss 352.2473\n",
      "Epoch [502/1000], Training Loss: 158.6571, Validation Loss 357.4330\n",
      "Epoch [503/1000], Training Loss: 158.5459, Validation Loss 348.4004\n",
      "Epoch [504/1000], Training Loss: 158.7632, Validation Loss 344.5325\n",
      "Epoch [505/1000], Training Loss: 158.6014, Validation Loss 345.9497\n",
      "Epoch [506/1000], Training Loss: 158.5651, Validation Loss 353.4386\n",
      "Epoch [507/1000], Training Loss: 158.5177, Validation Loss 357.0244\n",
      "Epoch [508/1000], Training Loss: 158.4909, Validation Loss 348.5068\n",
      "Epoch [509/1000], Training Loss: 158.4903, Validation Loss 352.5806\n",
      "Epoch [510/1000], Training Loss: 158.6427, Validation Loss 355.9247\n",
      "Epoch [511/1000], Training Loss: 158.3685, Validation Loss 354.2135\n",
      "Epoch [512/1000], Training Loss: 158.4635, Validation Loss 352.0464\n",
      "Epoch [513/1000], Training Loss: 158.3828, Validation Loss 350.7087\n",
      "Epoch [514/1000], Training Loss: 158.4280, Validation Loss 352.6965\n",
      "Epoch [515/1000], Training Loss: 158.4724, Validation Loss 356.1264\n",
      "Epoch [516/1000], Training Loss: 158.4168, Validation Loss 355.4546\n",
      "Epoch [517/1000], Training Loss: 158.3746, Validation Loss 353.0516\n",
      "Epoch [518/1000], Training Loss: 158.3506, Validation Loss 352.6168\n",
      "Epoch [519/1000], Training Loss: 158.3703, Validation Loss 355.5214\n",
      "Epoch [520/1000], Training Loss: 158.5917, Validation Loss 350.3703\n",
      "Epoch [521/1000], Training Loss: 158.4102, Validation Loss 344.4478\n",
      "Epoch [522/1000], Training Loss: 158.3967, Validation Loss 349.3529\n",
      "Epoch [523/1000], Training Loss: 158.2983, Validation Loss 355.9014\n",
      "Epoch [524/1000], Training Loss: 158.3722, Validation Loss 359.8777\n",
      "Epoch [525/1000], Training Loss: 158.2544, Validation Loss 357.0789\n",
      "Epoch [526/1000], Training Loss: 158.2583, Validation Loss 357.7902\n",
      "Epoch [527/1000], Training Loss: 158.2397, Validation Loss 357.8897\n",
      "Epoch [528/1000], Training Loss: 158.3187, Validation Loss 353.5158\n",
      "Epoch [529/1000], Training Loss: 158.2767, Validation Loss 354.3997\n",
      "Epoch [530/1000], Training Loss: 158.3254, Validation Loss 354.1715\n",
      "Epoch [531/1000], Training Loss: 158.2846, Validation Loss 351.9397\n",
      "Epoch [532/1000], Training Loss: 158.2872, Validation Loss 350.3931\n",
      "Epoch [533/1000], Training Loss: 158.2255, Validation Loss 349.7441\n",
      "Epoch [534/1000], Training Loss: 159.1307, Validation Loss 359.4752\n",
      "Epoch [535/1000], Training Loss: 158.4012, Validation Loss 345.8725\n",
      "Epoch [536/1000], Training Loss: 158.5642, Validation Loss 349.9949\n",
      "Epoch [537/1000], Training Loss: 158.2987, Validation Loss 351.8413\n",
      "Epoch [538/1000], Training Loss: 158.2355, Validation Loss 348.9335\n",
      "Epoch [539/1000], Training Loss: 158.2604, Validation Loss 347.8628\n",
      "Epoch [540/1000], Training Loss: 158.3145, Validation Loss 345.3001\n",
      "Epoch [541/1000], Training Loss: 158.2536, Validation Loss 346.7094\n",
      "Epoch [542/1000], Training Loss: 158.2526, Validation Loss 347.8320\n",
      "Epoch [543/1000], Training Loss: 158.1749, Validation Loss 348.3436\n",
      "Epoch [544/1000], Training Loss: 158.1689, Validation Loss 349.7215\n",
      "Epoch [545/1000], Training Loss: 158.2168, Validation Loss 348.9519\n",
      "Epoch [546/1000], Training Loss: 158.2103, Validation Loss 347.2575\n",
      "Epoch [547/1000], Training Loss: 158.3650, Validation Loss 346.8746\n",
      "Epoch [548/1000], Training Loss: 158.2322, Validation Loss 346.8968\n",
      "Epoch [549/1000], Training Loss: 158.1676, Validation Loss 349.4328\n",
      "Epoch [550/1000], Training Loss: 158.2073, Validation Loss 349.2098\n",
      "Epoch [551/1000], Training Loss: 158.1527, Validation Loss 350.3895\n",
      "Epoch [552/1000], Training Loss: 158.1808, Validation Loss 350.6108\n",
      "Epoch [553/1000], Training Loss: 158.1597, Validation Loss 349.8811\n",
      "Epoch [554/1000], Training Loss: 158.1823, Validation Loss 350.2360\n",
      "Epoch [555/1000], Training Loss: 158.1699, Validation Loss 350.1371\n",
      "Epoch [556/1000], Training Loss: 158.1352, Validation Loss 348.9718\n",
      "Epoch [557/1000], Training Loss: 158.1800, Validation Loss 348.5133\n",
      "Epoch [558/1000], Training Loss: 158.3058, Validation Loss 351.2861\n",
      "Epoch [559/1000], Training Loss: 158.2572, Validation Loss 354.6792\n",
      "Epoch [560/1000], Training Loss: 158.1817, Validation Loss 353.8622\n",
      "Epoch [561/1000], Training Loss: 158.1626, Validation Loss 352.9869\n",
      "Epoch [562/1000], Training Loss: 158.1738, Validation Loss 351.9361\n",
      "Epoch [563/1000], Training Loss: 158.1451, Validation Loss 350.9080\n",
      "Epoch [564/1000], Training Loss: 158.1442, Validation Loss 350.1892\n",
      "Epoch [565/1000], Training Loss: 158.1555, Validation Loss 350.6414\n",
      "Epoch [566/1000], Training Loss: 158.1867, Validation Loss 351.0844\n",
      "Epoch [567/1000], Training Loss: 158.2873, Validation Loss 353.6472\n",
      "Epoch [568/1000], Training Loss: 158.2605, Validation Loss 356.2239\n",
      "Epoch [569/1000], Training Loss: 158.1569, Validation Loss 355.2011\n",
      "Epoch [570/1000], Training Loss: 158.1587, Validation Loss 351.3468\n",
      "Epoch [571/1000], Training Loss: 158.2228, Validation Loss 348.5678\n",
      "Epoch [572/1000], Training Loss: 158.1782, Validation Loss 347.9434\n",
      "Epoch [573/1000], Training Loss: 158.1566, Validation Loss 347.0422\n",
      "Epoch [574/1000], Training Loss: 158.1484, Validation Loss 348.8512\n",
      "Epoch [575/1000], Training Loss: 158.5449, Validation Loss 350.8544\n",
      "Epoch [576/1000], Training Loss: 158.2086, Validation Loss 348.0157\n",
      "Epoch [577/1000], Training Loss: 158.1701, Validation Loss 347.1039\n",
      "Epoch [578/1000], Training Loss: 158.1691, Validation Loss 347.8049\n",
      "Epoch [579/1000], Training Loss: 158.2482, Validation Loss 350.3131\n",
      "Epoch [580/1000], Training Loss: 158.1548, Validation Loss 352.1308\n",
      "Epoch [581/1000], Training Loss: 158.1101, Validation Loss 352.3467\n",
      "Epoch [582/1000], Training Loss: 158.1037, Validation Loss 351.9360\n",
      "Epoch [583/1000], Training Loss: 158.0820, Validation Loss 350.2923\n",
      "Epoch [584/1000], Training Loss: 158.1392, Validation Loss 348.7241\n",
      "Epoch [585/1000], Training Loss: 158.1085, Validation Loss 350.3865\n",
      "Epoch [586/1000], Training Loss: 158.1629, Validation Loss 352.4018\n",
      "Epoch [587/1000], Training Loss: 158.1226, Validation Loss 353.0639\n",
      "Epoch [588/1000], Training Loss: 158.1190, Validation Loss 352.1558\n",
      "Epoch [589/1000], Training Loss: 158.1651, Validation Loss 349.1786\n",
      "Epoch [590/1000], Training Loss: 158.1201, Validation Loss 349.2687\n",
      "Epoch [591/1000], Training Loss: 158.2894, Validation Loss 354.5497\n",
      "Epoch [592/1000], Training Loss: 158.2280, Validation Loss 359.5242\n",
      "Epoch [593/1000], Training Loss: 158.2410, Validation Loss 356.4439\n",
      "Epoch [594/1000], Training Loss: 158.1523, Validation Loss 354.2461\n",
      "Epoch [595/1000], Training Loss: 158.2687, Validation Loss 353.8497\n",
      "Epoch [596/1000], Training Loss: 158.1627, Validation Loss 353.4348\n",
      "Epoch [597/1000], Training Loss: 158.2017, Validation Loss 351.3736\n",
      "Epoch [598/1000], Training Loss: 158.1379, Validation Loss 349.0910\n",
      "Epoch [599/1000], Training Loss: 158.9326, Validation Loss 333.7730\n",
      "Epoch [600/1000], Training Loss: 159.2460, Validation Loss 351.2870\n",
      "Epoch [601/1000], Training Loss: 158.5332, Validation Loss 354.5667\n",
      "Epoch [602/1000], Training Loss: 158.5248, Validation Loss 344.9481\n",
      "Epoch [603/1000], Training Loss: 158.4464, Validation Loss 343.6396\n",
      "Epoch [604/1000], Training Loss: 158.3077, Validation Loss 343.1654\n",
      "Epoch [605/1000], Training Loss: 158.2145, Validation Loss 340.9104\n",
      "Epoch [606/1000], Training Loss: 158.1300, Validation Loss 341.8616\n",
      "Epoch [607/1000], Training Loss: 158.2145, Validation Loss 343.0589\n",
      "Epoch [608/1000], Training Loss: 158.1135, Validation Loss 345.9547\n",
      "Epoch [609/1000], Training Loss: 158.1526, Validation Loss 347.2632\n",
      "Epoch [610/1000], Training Loss: 158.1179, Validation Loss 346.8148\n",
      "Epoch [611/1000], Training Loss: 158.1630, Validation Loss 349.7109\n",
      "Epoch [612/1000], Training Loss: 158.1425, Validation Loss 349.3718\n",
      "Epoch [613/1000], Training Loss: 158.1439, Validation Loss 347.9116\n",
      "Epoch [614/1000], Training Loss: 158.1229, Validation Loss 347.7223\n",
      "Epoch [615/1000], Training Loss: 158.1812, Validation Loss 348.8532\n",
      "Epoch [616/1000], Training Loss: 158.2389, Validation Loss 350.1832\n",
      "Epoch [617/1000], Training Loss: 158.1929, Validation Loss 351.9149\n",
      "Epoch [618/1000], Training Loss: 158.0902, Validation Loss 351.6751\n",
      "Epoch [619/1000], Training Loss: 158.1835, Validation Loss 350.8165\n",
      "Epoch [620/1000], Training Loss: 172.1266, Validation Loss 333.0732\n",
      "Epoch [621/1000], Training Loss: 173.8222, Validation Loss 370.7009\n",
      "Epoch [622/1000], Training Loss: 181.1405, Validation Loss 298.1404\n",
      "Epoch [623/1000], Training Loss: 181.5433, Validation Loss 326.8967\n",
      "Epoch [624/1000], Training Loss: 174.5229, Validation Loss 339.4755\n",
      "Epoch [625/1000], Training Loss: 169.8993, Validation Loss 382.3078\n",
      "Epoch [626/1000], Training Loss: 162.7404, Validation Loss 342.9808\n",
      "Epoch [627/1000], Training Loss: 163.2967, Validation Loss 357.0214\n",
      "Epoch [628/1000], Training Loss: 162.2709, Validation Loss 356.1674\n",
      "Epoch [629/1000], Training Loss: 160.3151, Validation Loss 363.2393\n",
      "Epoch [630/1000], Training Loss: 160.7993, Validation Loss 356.2856\n",
      "Epoch [631/1000], Training Loss: 160.1132, Validation Loss 373.0286\n",
      "Epoch [632/1000], Training Loss: 159.1632, Validation Loss 352.6645\n",
      "Epoch [633/1000], Training Loss: 159.7146, Validation Loss 352.1630\n",
      "Epoch [634/1000], Training Loss: 159.0526, Validation Loss 342.7335\n",
      "Epoch [635/1000], Training Loss: 159.3897, Validation Loss 356.6089\n",
      "Epoch [636/1000], Training Loss: 159.3960, Validation Loss 355.3484\n",
      "Epoch [637/1000], Training Loss: 158.7792, Validation Loss 350.2633\n",
      "Epoch [638/1000], Training Loss: 159.0086, Validation Loss 352.0790\n",
      "Epoch [639/1000], Training Loss: 158.6764, Validation Loss 348.0944\n",
      "Epoch [640/1000], Training Loss: 158.6060, Validation Loss 347.1049\n",
      "Epoch [641/1000], Training Loss: 158.3160, Validation Loss 351.6259\n",
      "Epoch [642/1000], Training Loss: 158.4936, Validation Loss 350.3492\n",
      "Epoch [643/1000], Training Loss: 158.3867, Validation Loss 347.9883\n",
      "Epoch [644/1000], Training Loss: 158.4553, Validation Loss 350.8627\n",
      "Epoch [645/1000], Training Loss: 158.3504, Validation Loss 354.2180\n",
      "Epoch [646/1000], Training Loss: 158.3996, Validation Loss 353.5168\n",
      "Epoch [647/1000], Training Loss: 158.2616, Validation Loss 351.2029\n",
      "Epoch [648/1000], Training Loss: 158.2724, Validation Loss 351.6250\n",
      "Epoch [649/1000], Training Loss: 158.3626, Validation Loss 353.3175\n",
      "Epoch [650/1000], Training Loss: 158.2408, Validation Loss 354.5581\n",
      "Epoch [651/1000], Training Loss: 158.5525, Validation Loss 356.3816\n",
      "Epoch [652/1000], Training Loss: 158.2886, Validation Loss 358.6786\n",
      "Epoch [653/1000], Training Loss: 158.3766, Validation Loss 359.9066\n",
      "Epoch [654/1000], Training Loss: 158.2236, Validation Loss 361.5656\n",
      "Epoch [655/1000], Training Loss: 158.2243, Validation Loss 362.4525\n",
      "Epoch [656/1000], Training Loss: 158.2546, Validation Loss 365.0582\n",
      "Epoch [657/1000], Training Loss: 158.1546, Validation Loss 366.0202\n",
      "Epoch [658/1000], Training Loss: 158.5930, Validation Loss 356.9528\n",
      "Epoch [659/1000], Training Loss: 158.3089, Validation Loss 346.4182\n",
      "Epoch [660/1000], Training Loss: 158.3160, Validation Loss 344.1365\n",
      "Epoch [661/1000], Training Loss: 158.2940, Validation Loss 347.4852\n",
      "Epoch [662/1000], Training Loss: 158.2955, Validation Loss 351.9065\n",
      "Epoch [663/1000], Training Loss: 158.2443, Validation Loss 354.2363\n",
      "Epoch [664/1000], Training Loss: 158.4055, Validation Loss 357.0904\n",
      "Epoch [665/1000], Training Loss: 158.2647, Validation Loss 354.9212\n",
      "Epoch [666/1000], Training Loss: 158.1960, Validation Loss 355.3228\n",
      "Epoch [667/1000], Training Loss: 158.6889, Validation Loss 348.2487\n",
      "Epoch [668/1000], Training Loss: 158.7942, Validation Loss 361.9664\n",
      "Epoch [669/1000], Training Loss: 158.8949, Validation Loss 359.2402\n",
      "Epoch [670/1000], Training Loss: 158.5530, Validation Loss 351.1635\n",
      "Epoch [671/1000], Training Loss: 158.2922, Validation Loss 355.1097\n",
      "Epoch [672/1000], Training Loss: 158.3920, Validation Loss 349.7428\n",
      "Epoch [673/1000], Training Loss: 158.3022, Validation Loss 348.3500\n",
      "Epoch [674/1000], Training Loss: 158.2911, Validation Loss 348.9623\n",
      "Epoch [675/1000], Training Loss: 158.3503, Validation Loss 350.6513\n",
      "Epoch [676/1000], Training Loss: 158.2155, Validation Loss 346.5814\n",
      "Epoch [677/1000], Training Loss: 158.2964, Validation Loss 342.8470\n",
      "Epoch [678/1000], Training Loss: 158.2273, Validation Loss 343.2220\n",
      "Epoch [679/1000], Training Loss: 158.2910, Validation Loss 345.9323\n",
      "Epoch [680/1000], Training Loss: 158.1662, Validation Loss 349.6655\n",
      "Epoch [681/1000], Training Loss: 158.1964, Validation Loss 349.9145\n",
      "Epoch [682/1000], Training Loss: 158.2574, Validation Loss 350.3700\n",
      "Epoch [683/1000], Training Loss: 158.1600, Validation Loss 350.7839\n",
      "Epoch [684/1000], Training Loss: 158.4293, Validation Loss 359.4819\n",
      "Epoch [685/1000], Training Loss: 158.3771, Validation Loss 369.1277\n",
      "Epoch [686/1000], Training Loss: 158.2577, Validation Loss 363.6046\n",
      "Epoch [687/1000], Training Loss: 158.1976, Validation Loss 365.8526\n",
      "Epoch [688/1000], Training Loss: 158.1786, Validation Loss 363.9345\n",
      "Epoch [689/1000], Training Loss: 158.1650, Validation Loss 359.3892\n",
      "Epoch [690/1000], Training Loss: 158.1345, Validation Loss 360.2811\n",
      "Epoch [691/1000], Training Loss: 158.1821, Validation Loss 360.4624\n",
      "Epoch [692/1000], Training Loss: 158.2063, Validation Loss 359.2450\n",
      "Epoch [693/1000], Training Loss: 158.1602, Validation Loss 359.0112\n",
      "Epoch [694/1000], Training Loss: 158.1684, Validation Loss 361.0614\n",
      "Epoch [695/1000], Training Loss: 158.1455, Validation Loss 360.8394\n",
      "Epoch [696/1000], Training Loss: 158.1459, Validation Loss 358.3758\n",
      "Epoch [697/1000], Training Loss: 158.0926, Validation Loss 358.6299\n",
      "Epoch [698/1000], Training Loss: 158.3893, Validation Loss 359.8277\n",
      "Epoch [699/1000], Training Loss: 158.1515, Validation Loss 361.7988\n",
      "Epoch [700/1000], Training Loss: 158.1815, Validation Loss 363.2888\n",
      "Epoch [701/1000], Training Loss: 158.1687, Validation Loss 364.8991\n",
      "Epoch [702/1000], Training Loss: 158.1253, Validation Loss 366.4722\n",
      "Epoch [703/1000], Training Loss: 158.1285, Validation Loss 367.7607\n",
      "Epoch [704/1000], Training Loss: 158.1888, Validation Loss 369.1966\n",
      "Epoch [705/1000], Training Loss: 158.1436, Validation Loss 365.8070\n",
      "Epoch [706/1000], Training Loss: 158.1235, Validation Loss 363.0727\n",
      "Epoch [707/1000], Training Loss: 158.2135, Validation Loss 361.7436\n",
      "Epoch [708/1000], Training Loss: 158.1233, Validation Loss 363.5176\n",
      "Epoch [709/1000], Training Loss: 158.1838, Validation Loss 366.9476\n",
      "Epoch [710/1000], Training Loss: 158.1812, Validation Loss 364.3411\n",
      "Epoch [711/1000], Training Loss: 158.3822, Validation Loss 357.7500\n",
      "Epoch [712/1000], Training Loss: 158.2202, Validation Loss 358.0724\n",
      "Epoch [713/1000], Training Loss: 158.1544, Validation Loss 358.0227\n",
      "Epoch [714/1000], Training Loss: 158.1104, Validation Loss 356.5996\n",
      "Epoch [715/1000], Training Loss: 158.1467, Validation Loss 356.3588\n",
      "Epoch [716/1000], Training Loss: 158.1185, Validation Loss 357.7907\n",
      "Epoch [717/1000], Training Loss: 158.0905, Validation Loss 358.2797\n",
      "Epoch [718/1000], Training Loss: 158.1130, Validation Loss 359.1685\n",
      "Epoch [719/1000], Training Loss: 158.1643, Validation Loss 358.3806\n",
      "Epoch [720/1000], Training Loss: 158.1355, Validation Loss 357.2155\n",
      "Epoch [721/1000], Training Loss: 158.0870, Validation Loss 358.1802\n",
      "Epoch [722/1000], Training Loss: 158.1493, Validation Loss 359.0747\n",
      "Epoch [723/1000], Training Loss: 158.1172, Validation Loss 358.6529\n",
      "Epoch [724/1000], Training Loss: 158.1710, Validation Loss 360.8285\n",
      "Epoch [725/1000], Training Loss: 158.1587, Validation Loss 360.5468\n",
      "Epoch [726/1000], Training Loss: 158.1149, Validation Loss 360.0119\n",
      "Epoch [727/1000], Training Loss: 158.1145, Validation Loss 358.7570\n",
      "Epoch [728/1000], Training Loss: 158.1019, Validation Loss 359.7007\n",
      "Epoch [729/1000], Training Loss: 158.5557, Validation Loss 379.0412\n",
      "Epoch [730/1000], Training Loss: 158.6386, Validation Loss 371.9692\n",
      "Epoch [731/1000], Training Loss: 158.3312, Validation Loss 367.3427\n",
      "Epoch [732/1000], Training Loss: 158.4223, Validation Loss 370.3703\n",
      "Epoch [733/1000], Training Loss: 158.4267, Validation Loss 361.2034\n",
      "Epoch [734/1000], Training Loss: 158.2156, Validation Loss 357.1682\n",
      "Epoch [735/1000], Training Loss: 158.1483, Validation Loss 361.5382\n",
      "Epoch [736/1000], Training Loss: 158.1354, Validation Loss 364.6857\n",
      "Epoch [737/1000], Training Loss: 158.1779, Validation Loss 362.8813\n",
      "Epoch [738/1000], Training Loss: 158.1752, Validation Loss 363.7128\n",
      "Epoch [739/1000], Training Loss: 158.2695, Validation Loss 374.0503\n",
      "Epoch [740/1000], Training Loss: 158.2488, Validation Loss 370.9625\n",
      "Epoch [741/1000], Training Loss: 158.1788, Validation Loss 365.7305\n",
      "Epoch [742/1000], Training Loss: 158.1495, Validation Loss 365.1160\n",
      "Epoch [743/1000], Training Loss: 158.1562, Validation Loss 363.8822\n",
      "Epoch [744/1000], Training Loss: 158.1350, Validation Loss 362.8344\n",
      "Epoch [745/1000], Training Loss: 158.2521, Validation Loss 360.2430\n",
      "Epoch [746/1000], Training Loss: 158.1404, Validation Loss 367.5874\n",
      "Epoch [747/1000], Training Loss: 158.2075, Validation Loss 366.6651\n",
      "Epoch [748/1000], Training Loss: 158.1482, Validation Loss 367.3979\n",
      "Epoch [749/1000], Training Loss: 158.1091, Validation Loss 371.0118\n",
      "Epoch [750/1000], Training Loss: 158.0954, Validation Loss 369.8614\n",
      "Epoch [751/1000], Training Loss: 158.1364, Validation Loss 369.8607\n",
      "Epoch [752/1000], Training Loss: 158.1077, Validation Loss 369.5155\n",
      "Epoch [753/1000], Training Loss: 158.0843, Validation Loss 368.1251\n",
      "Epoch [754/1000], Training Loss: 158.0856, Validation Loss 367.8760\n",
      "Epoch [755/1000], Training Loss: 158.0765, Validation Loss 368.1216\n",
      "Epoch [756/1000], Training Loss: 158.1031, Validation Loss 370.9377\n",
      "Epoch [757/1000], Training Loss: 158.0772, Validation Loss 371.1062\n",
      "Epoch [758/1000], Training Loss: 158.0923, Validation Loss 369.5720\n",
      "Epoch [759/1000], Training Loss: 158.0733, Validation Loss 366.8875\n",
      "Epoch [760/1000], Training Loss: 158.0693, Validation Loss 365.6293\n",
      "Epoch [761/1000], Training Loss: 158.1781, Validation Loss 362.7541\n",
      "Epoch [762/1000], Training Loss: 158.1574, Validation Loss 354.0364\n",
      "Epoch [763/1000], Training Loss: 158.0714, Validation Loss 351.2136\n",
      "Epoch [764/1000], Training Loss: 158.1310, Validation Loss 354.8303\n",
      "Epoch [765/1000], Training Loss: 158.0837, Validation Loss 355.7408\n",
      "Epoch [766/1000], Training Loss: 158.1108, Validation Loss 357.0865\n",
      "Epoch [767/1000], Training Loss: 158.0801, Validation Loss 358.2435\n",
      "Epoch [768/1000], Training Loss: 158.0666, Validation Loss 358.3670\n",
      "Epoch [769/1000], Training Loss: 158.0755, Validation Loss 357.7747\n",
      "Epoch [770/1000], Training Loss: 158.0671, Validation Loss 352.8323\n",
      "Epoch [771/1000], Training Loss: 158.0649, Validation Loss 351.5899\n",
      "Epoch [772/1000], Training Loss: 158.1225, Validation Loss 352.2374\n",
      "Epoch [773/1000], Training Loss: 158.0816, Validation Loss 354.3416\n",
      "Epoch [774/1000], Training Loss: 158.0931, Validation Loss 358.2672\n",
      "Epoch [775/1000], Training Loss: 158.0958, Validation Loss 357.7771\n",
      "Epoch [776/1000], Training Loss: 158.1234, Validation Loss 355.7544\n",
      "Epoch [777/1000], Training Loss: 158.1068, Validation Loss 356.4104\n",
      "Epoch [778/1000], Training Loss: 158.2178, Validation Loss 359.2698\n",
      "Epoch [779/1000], Training Loss: 158.1626, Validation Loss 361.0370\n",
      "Epoch [780/1000], Training Loss: 158.1339, Validation Loss 357.6470\n",
      "Epoch [781/1000], Training Loss: 158.0901, Validation Loss 357.4640\n",
      "Epoch [782/1000], Training Loss: 158.1127, Validation Loss 359.5620\n",
      "Epoch [783/1000], Training Loss: 158.0645, Validation Loss 359.8992\n",
      "Epoch [784/1000], Training Loss: 158.0802, Validation Loss 359.6445\n",
      "Epoch [785/1000], Training Loss: 158.1025, Validation Loss 359.2960\n",
      "Epoch [786/1000], Training Loss: 158.0610, Validation Loss 361.2981\n",
      "Epoch [787/1000], Training Loss: 158.1281, Validation Loss 362.6413\n",
      "Epoch [788/1000], Training Loss: 158.0579, Validation Loss 360.9367\n",
      "Epoch [789/1000], Training Loss: 158.1268, Validation Loss 353.1479\n",
      "Epoch [790/1000], Training Loss: 158.0686, Validation Loss 355.8920\n",
      "Epoch [791/1000], Training Loss: 158.0653, Validation Loss 366.0756\n",
      "Epoch [792/1000], Training Loss: 158.1231, Validation Loss 367.4668\n",
      "Epoch [793/1000], Training Loss: 158.0982, Validation Loss 366.5996\n",
      "Epoch [794/1000], Training Loss: 158.0729, Validation Loss 363.8814\n",
      "Epoch [795/1000], Training Loss: 158.0797, Validation Loss 362.9223\n",
      "Epoch [796/1000], Training Loss: 158.0671, Validation Loss 363.5258\n",
      "Epoch [797/1000], Training Loss: 158.0279, Validation Loss 364.2600\n",
      "Epoch [798/1000], Training Loss: 158.1002, Validation Loss 366.5733\n",
      "Epoch [799/1000], Training Loss: 158.0551, Validation Loss 363.2226\n",
      "Epoch [800/1000], Training Loss: 158.1249, Validation Loss 364.5573\n",
      "Epoch [801/1000], Training Loss: 158.0471, Validation Loss 361.2009\n",
      "Epoch [802/1000], Training Loss: 158.0573, Validation Loss 360.5300\n",
      "Epoch [803/1000], Training Loss: 158.0794, Validation Loss 351.7772\n",
      "Epoch [804/1000], Training Loss: 158.0562, Validation Loss 351.6949\n",
      "Epoch [805/1000], Training Loss: 158.0713, Validation Loss 351.7021\n",
      "Epoch [806/1000], Training Loss: 158.0822, Validation Loss 352.7796\n",
      "Epoch [807/1000], Training Loss: 158.0571, Validation Loss 351.8855\n",
      "Epoch [808/1000], Training Loss: 158.0435, Validation Loss 351.0674\n",
      "Epoch [809/1000], Training Loss: 158.0607, Validation Loss 351.0705\n",
      "Epoch [810/1000], Training Loss: 158.0350, Validation Loss 352.0291\n",
      "Epoch [811/1000], Training Loss: 158.0649, Validation Loss 354.6852\n",
      "Epoch [812/1000], Training Loss: 158.0544, Validation Loss 356.5364\n",
      "Epoch [813/1000], Training Loss: 158.0516, Validation Loss 354.9803\n",
      "Epoch [814/1000], Training Loss: 158.0244, Validation Loss 355.5072\n",
      "Epoch [815/1000], Training Loss: 158.0759, Validation Loss 351.1156\n",
      "Epoch [816/1000], Training Loss: 158.0306, Validation Loss 353.4660\n",
      "Epoch [817/1000], Training Loss: 158.1062, Validation Loss 355.9334\n",
      "Epoch [818/1000], Training Loss: 158.0210, Validation Loss 354.2672\n",
      "Epoch [819/1000], Training Loss: 158.0705, Validation Loss 355.5058\n",
      "Epoch [820/1000], Training Loss: 158.0491, Validation Loss 358.4868\n",
      "Epoch [821/1000], Training Loss: 158.0495, Validation Loss 362.5897\n",
      "Epoch [822/1000], Training Loss: 158.0674, Validation Loss 358.4522\n",
      "Epoch [823/1000], Training Loss: 158.0782, Validation Loss 353.3976\n",
      "Epoch [824/1000], Training Loss: 158.1057, Validation Loss 348.1739\n",
      "Epoch [825/1000], Training Loss: 158.1011, Validation Loss 347.5925\n",
      "Epoch [826/1000], Training Loss: 158.0358, Validation Loss 350.4723\n",
      "Epoch [827/1000], Training Loss: 158.0659, Validation Loss 355.3092\n",
      "Epoch [828/1000], Training Loss: 158.1677, Validation Loss 356.6126\n",
      "Epoch [829/1000], Training Loss: 158.1155, Validation Loss 358.5474\n",
      "Epoch [830/1000], Training Loss: 158.0857, Validation Loss 354.2409\n",
      "Epoch [831/1000], Training Loss: 158.0407, Validation Loss 353.5012\n",
      "Epoch [832/1000], Training Loss: 158.0396, Validation Loss 355.6109\n",
      "Epoch [833/1000], Training Loss: 158.0572, Validation Loss 355.9141\n",
      "Epoch [834/1000], Training Loss: 158.0763, Validation Loss 357.7224\n",
      "Epoch [835/1000], Training Loss: 158.2331, Validation Loss 351.0332\n",
      "Epoch [836/1000], Training Loss: 158.1003, Validation Loss 354.2435\n",
      "Epoch [837/1000], Training Loss: 158.1064, Validation Loss 359.0966\n",
      "Epoch [838/1000], Training Loss: 158.0817, Validation Loss 357.7082\n",
      "Epoch [839/1000], Training Loss: 161.3200, Validation Loss 341.7306\n",
      "Epoch [840/1000], Training Loss: 158.8567, Validation Loss 342.6942\n",
      "Epoch [841/1000], Training Loss: 158.6742, Validation Loss 348.7496\n",
      "Epoch [842/1000], Training Loss: 164.2069, Validation Loss 374.8001\n",
      "Epoch [843/1000], Training Loss: 175.1640, Validation Loss 345.6297\n",
      "Epoch [844/1000], Training Loss: 179.1004, Validation Loss 312.2491\n",
      "Epoch [845/1000], Training Loss: 178.8915, Validation Loss 329.5966\n",
      "Epoch [846/1000], Training Loss: 175.4321, Validation Loss 351.7525\n",
      "Epoch [847/1000], Training Loss: 171.1113, Validation Loss 325.5619\n",
      "Epoch [848/1000], Training Loss: 169.4394, Validation Loss 330.3141\n",
      "Epoch [849/1000], Training Loss: 175.6000, Validation Loss 347.3929\n",
      "Epoch [850/1000], Training Loss: 169.2021, Validation Loss 328.6197\n",
      "Epoch [851/1000], Training Loss: 167.2390, Validation Loss 330.8553\n",
      "Epoch [852/1000], Training Loss: 165.0682, Validation Loss 348.2129\n",
      "Epoch [853/1000], Training Loss: 166.4860, Validation Loss 349.0536\n",
      "Epoch [854/1000], Training Loss: 162.5124, Validation Loss 349.5218\n",
      "Epoch [855/1000], Training Loss: 161.4641, Validation Loss 359.2804\n",
      "Epoch [856/1000], Training Loss: 163.9912, Validation Loss 321.2843\n",
      "Epoch [857/1000], Training Loss: 161.7170, Validation Loss 345.3835\n",
      "Epoch [858/1000], Training Loss: 160.3328, Validation Loss 362.0566\n",
      "Epoch [859/1000], Training Loss: 160.1870, Validation Loss 369.9477\n",
      "Epoch [860/1000], Training Loss: 159.7889, Validation Loss 376.7625\n",
      "Epoch [861/1000], Training Loss: 159.9149, Validation Loss 371.9089\n",
      "Epoch [862/1000], Training Loss: 159.7538, Validation Loss 343.6143\n",
      "Epoch [863/1000], Training Loss: 160.6724, Validation Loss 344.9255\n",
      "Epoch [864/1000], Training Loss: 159.6493, Validation Loss 340.6643\n",
      "Epoch [865/1000], Training Loss: 159.1076, Validation Loss 352.0343\n",
      "Epoch [866/1000], Training Loss: 158.7610, Validation Loss 350.2012\n",
      "Epoch [867/1000], Training Loss: 158.4368, Validation Loss 345.5852\n",
      "Epoch [868/1000], Training Loss: 158.6052, Validation Loss 335.6124\n",
      "Epoch [869/1000], Training Loss: 158.4316, Validation Loss 336.2490\n",
      "Epoch [870/1000], Training Loss: 158.4706, Validation Loss 342.4039\n",
      "Epoch [871/1000], Training Loss: 158.4967, Validation Loss 349.0473\n",
      "Epoch [872/1000], Training Loss: 158.4370, Validation Loss 349.9637\n",
      "Epoch [873/1000], Training Loss: 158.4967, Validation Loss 347.8931\n",
      "Epoch [874/1000], Training Loss: 158.3240, Validation Loss 347.2562\n",
      "Epoch [875/1000], Training Loss: 158.6421, Validation Loss 349.4686\n",
      "Epoch [876/1000], Training Loss: 158.3047, Validation Loss 356.4519\n",
      "Epoch [877/1000], Training Loss: 158.3266, Validation Loss 355.5387\n",
      "Epoch [878/1000], Training Loss: 158.3082, Validation Loss 354.7258\n",
      "Epoch [879/1000], Training Loss: 158.1900, Validation Loss 355.5111\n",
      "Epoch [880/1000], Training Loss: 158.2337, Validation Loss 353.7561\n",
      "Epoch [881/1000], Training Loss: 158.2352, Validation Loss 352.3042\n",
      "Epoch [882/1000], Training Loss: 158.2156, Validation Loss 352.7946\n",
      "Epoch [883/1000], Training Loss: 158.1919, Validation Loss 353.4319\n",
      "Epoch [884/1000], Training Loss: 158.2686, Validation Loss 354.2141\n",
      "Epoch [885/1000], Training Loss: 158.1948, Validation Loss 356.0513\n",
      "Epoch [886/1000], Training Loss: 158.1549, Validation Loss 356.9757\n",
      "Epoch [887/1000], Training Loss: 158.1277, Validation Loss 355.4794\n",
      "Epoch [888/1000], Training Loss: 158.1560, Validation Loss 354.9700\n",
      "Epoch [889/1000], Training Loss: 158.3851, Validation Loss 347.8996\n",
      "Epoch [890/1000], Training Loss: 158.2848, Validation Loss 345.3006\n",
      "Epoch [891/1000], Training Loss: 158.2071, Validation Loss 342.4611\n",
      "Epoch [892/1000], Training Loss: 158.4594, Validation Loss 341.6626\n",
      "Epoch [893/1000], Training Loss: 158.2060, Validation Loss 345.1852\n",
      "Epoch [894/1000], Training Loss: 158.2549, Validation Loss 346.9939\n",
      "Epoch [895/1000], Training Loss: 158.1841, Validation Loss 346.6192\n",
      "Epoch [896/1000], Training Loss: 158.2593, Validation Loss 345.8812\n",
      "Epoch [897/1000], Training Loss: 158.1473, Validation Loss 344.9532\n",
      "Epoch [898/1000], Training Loss: 158.1522, Validation Loss 346.0027\n",
      "Epoch [899/1000], Training Loss: 158.3272, Validation Loss 350.5591\n",
      "Epoch [900/1000], Training Loss: 158.2109, Validation Loss 357.2916\n",
      "Epoch [901/1000], Training Loss: 158.3976, Validation Loss 340.0815\n",
      "Epoch [902/1000], Training Loss: 158.3640, Validation Loss 345.5107\n",
      "Epoch [903/1000], Training Loss: 158.1450, Validation Loss 348.0745\n",
      "Epoch [904/1000], Training Loss: 158.1642, Validation Loss 349.0362\n",
      "Epoch [905/1000], Training Loss: 158.1353, Validation Loss 349.4164\n",
      "Epoch [906/1000], Training Loss: 158.1781, Validation Loss 351.7120\n",
      "Epoch [907/1000], Training Loss: 158.1094, Validation Loss 352.4058\n",
      "Epoch [908/1000], Training Loss: 158.1352, Validation Loss 348.4127\n",
      "Epoch [909/1000], Training Loss: 158.1161, Validation Loss 348.8869\n",
      "Epoch [910/1000], Training Loss: 158.1131, Validation Loss 349.0098\n",
      "Epoch [911/1000], Training Loss: 158.1521, Validation Loss 350.8353\n",
      "Epoch [912/1000], Training Loss: 158.1012, Validation Loss 351.4148\n",
      "Epoch [913/1000], Training Loss: 158.1031, Validation Loss 351.6169\n",
      "Epoch [914/1000], Training Loss: 158.1188, Validation Loss 350.6485\n",
      "Epoch [915/1000], Training Loss: 158.1399, Validation Loss 351.1122\n",
      "Epoch [916/1000], Training Loss: 158.0734, Validation Loss 353.1754\n",
      "Epoch [917/1000], Training Loss: 158.1019, Validation Loss 352.9777\n",
      "Epoch [918/1000], Training Loss: 158.1142, Validation Loss 350.7424\n",
      "Epoch [919/1000], Training Loss: 158.1041, Validation Loss 351.0164\n",
      "Epoch [920/1000], Training Loss: 158.0950, Validation Loss 351.7696\n",
      "Epoch [921/1000], Training Loss: 158.1264, Validation Loss 349.0661\n",
      "Epoch [922/1000], Training Loss: 158.1263, Validation Loss 351.2260\n",
      "Epoch [923/1000], Training Loss: 158.0952, Validation Loss 350.3036\n",
      "Epoch [924/1000], Training Loss: 158.0733, Validation Loss 349.8387\n",
      "Epoch [925/1000], Training Loss: 158.1221, Validation Loss 350.7681\n",
      "Epoch [926/1000], Training Loss: 158.0734, Validation Loss 352.5629\n",
      "Epoch [927/1000], Training Loss: 158.0833, Validation Loss 353.7544\n",
      "Epoch [928/1000], Training Loss: 158.1041, Validation Loss 352.4549\n",
      "Epoch [929/1000], Training Loss: 158.0704, Validation Loss 353.1361\n",
      "Epoch [930/1000], Training Loss: 158.0700, Validation Loss 351.4067\n",
      "Epoch [931/1000], Training Loss: 158.0629, Validation Loss 349.9348\n",
      "Epoch [932/1000], Training Loss: 158.0659, Validation Loss 351.8383\n",
      "Epoch [933/1000], Training Loss: 158.0614, Validation Loss 352.2771\n",
      "Epoch [934/1000], Training Loss: 158.0892, Validation Loss 353.4080\n",
      "Epoch [935/1000], Training Loss: 158.0500, Validation Loss 355.4715\n",
      "Epoch [936/1000], Training Loss: 158.1061, Validation Loss 353.7665\n",
      "Epoch [937/1000], Training Loss: 158.1463, Validation Loss 350.4694\n",
      "Epoch [938/1000], Training Loss: 158.0633, Validation Loss 350.6507\n",
      "Epoch [939/1000], Training Loss: 158.0796, Validation Loss 350.5408\n",
      "Epoch [940/1000], Training Loss: 158.0625, Validation Loss 350.8253\n",
      "Epoch [941/1000], Training Loss: 158.1114, Validation Loss 351.9917\n",
      "Epoch [942/1000], Training Loss: 158.0682, Validation Loss 353.1552\n",
      "Epoch [943/1000], Training Loss: 158.0689, Validation Loss 351.6586\n",
      "Epoch [944/1000], Training Loss: 158.0659, Validation Loss 349.9050\n",
      "Epoch [945/1000], Training Loss: 158.0479, Validation Loss 351.1412\n",
      "Epoch [946/1000], Training Loss: 158.0494, Validation Loss 350.4694\n",
      "Epoch [947/1000], Training Loss: 158.0370, Validation Loss 352.4484\n",
      "Epoch [948/1000], Training Loss: 158.0482, Validation Loss 354.4682\n",
      "Epoch [949/1000], Training Loss: 158.0870, Validation Loss 355.1535\n",
      "Epoch [950/1000], Training Loss: 158.0605, Validation Loss 356.5476\n",
      "Epoch [951/1000], Training Loss: 158.0898, Validation Loss 353.1940\n",
      "Epoch [952/1000], Training Loss: 158.0330, Validation Loss 353.4669\n",
      "Epoch [953/1000], Training Loss: 158.0392, Validation Loss 353.3954\n",
      "Epoch [954/1000], Training Loss: 158.0507, Validation Loss 353.1647\n",
      "Epoch [955/1000], Training Loss: 158.0418, Validation Loss 353.5020\n",
      "Epoch [956/1000], Training Loss: 158.1339, Validation Loss 354.8122\n",
      "Epoch [957/1000], Training Loss: 158.0251, Validation Loss 354.7192\n",
      "Epoch [958/1000], Training Loss: 158.0331, Validation Loss 353.3640\n",
      "Epoch [959/1000], Training Loss: 158.0393, Validation Loss 351.7310\n",
      "Epoch [960/1000], Training Loss: 158.0402, Validation Loss 353.7996\n",
      "Epoch [961/1000], Training Loss: 158.0239, Validation Loss 353.0484\n",
      "Epoch [962/1000], Training Loss: 158.0336, Validation Loss 351.2873\n",
      "Epoch [963/1000], Training Loss: 158.0292, Validation Loss 351.4851\n",
      "Epoch [964/1000], Training Loss: 158.0472, Validation Loss 352.0677\n",
      "Epoch [965/1000], Training Loss: 158.0468, Validation Loss 351.7368\n",
      "Epoch [966/1000], Training Loss: 158.0660, Validation Loss 355.4132\n",
      "Epoch [967/1000], Training Loss: 158.0137, Validation Loss 356.4425\n",
      "Epoch [968/1000], Training Loss: 158.0576, Validation Loss 354.8390\n",
      "Epoch [969/1000], Training Loss: 158.0213, Validation Loss 353.6378\n",
      "Epoch [970/1000], Training Loss: 158.0345, Validation Loss 355.8709\n",
      "Epoch [971/1000], Training Loss: 158.0102, Validation Loss 356.6756\n",
      "Epoch [972/1000], Training Loss: 158.0368, Validation Loss 356.4905\n",
      "Epoch [973/1000], Training Loss: 157.9941, Validation Loss 355.9847\n",
      "Epoch [974/1000], Training Loss: 158.0242, Validation Loss 355.6586\n",
      "Epoch [975/1000], Training Loss: 158.0778, Validation Loss 356.0235\n",
      "Epoch [976/1000], Training Loss: 158.0924, Validation Loss 355.2026\n",
      "Epoch [977/1000], Training Loss: 158.0210, Validation Loss 354.0342\n",
      "Epoch [978/1000], Training Loss: 158.0136, Validation Loss 353.3632\n",
      "Epoch [979/1000], Training Loss: 158.0304, Validation Loss 352.5648\n",
      "Epoch [980/1000], Training Loss: 158.0457, Validation Loss 353.1482\n",
      "Epoch [981/1000], Training Loss: 158.0360, Validation Loss 353.9248\n",
      "Epoch [982/1000], Training Loss: 158.0075, Validation Loss 353.8455\n",
      "Epoch [983/1000], Training Loss: 158.0246, Validation Loss 353.1447\n",
      "Epoch [984/1000], Training Loss: 157.9983, Validation Loss 353.8848\n",
      "Epoch [985/1000], Training Loss: 158.0077, Validation Loss 352.7598\n",
      "Epoch [986/1000], Training Loss: 158.0087, Validation Loss 352.9415\n",
      "Epoch [987/1000], Training Loss: 158.0134, Validation Loss 354.6867\n",
      "Epoch [988/1000], Training Loss: 158.0417, Validation Loss 355.2308\n",
      "Epoch [989/1000], Training Loss: 158.0121, Validation Loss 353.9027\n",
      "Epoch [990/1000], Training Loss: 158.0031, Validation Loss 354.2976\n",
      "Epoch [991/1000], Training Loss: 158.0205, Validation Loss 356.5593\n",
      "Epoch [992/1000], Training Loss: 158.0691, Validation Loss 356.1396\n",
      "Epoch [993/1000], Training Loss: 158.0231, Validation Loss 357.3483\n",
      "Epoch [994/1000], Training Loss: 158.0208, Validation Loss 357.2211\n",
      "Epoch [995/1000], Training Loss: 157.9981, Validation Loss 357.7140\n",
      "Epoch [996/1000], Training Loss: 157.9964, Validation Loss 357.1524\n",
      "Epoch [997/1000], Training Loss: 158.0169, Validation Loss 357.4750\n",
      "Epoch [998/1000], Training Loss: 157.9941, Validation Loss 357.5246\n",
      "Epoch [999/1000], Training Loss: 158.0189, Validation Loss 357.6734\n",
      "Epoch [1000/1000], Training Loss: 157.9882, Validation Loss 359.4298\n",
      "Training done\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "x_val = np.load('x_val.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_val =np.load('y_val.npy')\n",
    "\n",
    "# print(x_train.shape)\n",
    "torch.cuda.set_device(3)\n",
    "device = \"cuda:3\"\n",
    "model= UNet(NB_BANDS, NB_CLASSES).to(device) \n",
    "train_losses, val_losses, x_train, y_train = train_net(model, device, x_train, y_train, x_val, y_val)\n",
    "# print(x_train)\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(), 'unet_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_BANDS      = 30\n",
    "NB_CLASSES    = 3   \n",
    "# CLASS_WEIGHTS = [2, 1, 1]\n",
    "NB_EPOCHS     = 100\n",
    "BATCH_SIZE    = 8\n",
    "UPCONV        = True\n",
    "PATCH_SIZE    = 224  # should be divisible by 16\n",
    "NB_TRAIN      = 800\n",
    "NB_VAL        = 200\n",
    "NB_TEST       = 200\n",
    "\n",
    "data_path = \"datas\"\n",
    "weight_path = 'weights'\n",
    "\n",
    "# def normalize(img):\n",
    "#     minv = img.min()\n",
    "#     maxv = img.max()\n",
    "#     return 2.0 * (img - minv) / (maxv - minv) - 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_418118/2584464002.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('unet_model.pth'))\n",
      "/tmp/ipykernel_418118/2584464002.py:70: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  patches = torch.Tensor(patches_list).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 30, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "def predict(x, model, patch_size=320, nb_classes=3):\n",
    "    img_height = x.shape[1]\n",
    "    img_width =  x.shape[2]\n",
    "    nb_channels = x.shape[0]\n",
    "    device = \"cuda:3\"\n",
    "    \n",
    "    nb_patches_vertical = math.ceil(img_height / patch_size)\n",
    "    nb_patches_horizontal = math.ceil(img_width / patch_size)\n",
    "    extended_height = patch_size * nb_patches_vertical\n",
    "    extended_width = patch_size * nb_patches_horizontal\n",
    "    ext_x = np.zeros((nb_channels, extended_height, extended_width), dtype=np.float32)\n",
    "\n",
    "    ext_x[:, :img_height, :img_width] = x\n",
    "    for i in range(img_height, extended_height):\n",
    "        mirror_i = img_height - (i - img_height) % img_height - 1\n",
    "        ext_x[:, i, :] = ext_x[:, mirror_i, :]\n",
    "\n",
    "    for j in range(img_width, extended_width):\n",
    "        mirror_j = img_width - (j - img_width) % img_width - 1\n",
    "        ext_x[:, :, j] = ext_x[:, :, mirror_j]\n",
    "\n",
    "    patches_list = []\n",
    "    predictions_list = []\n",
    "    predicted_classes_list = []\n",
    "\n",
    "    # for i in range(nb_patches_vertical):\n",
    "    #     for j in range(nb_patches_horizontal):\n",
    "    #         x0, x1 = i * patch_size, (i + 1) * patch_size\n",
    "    #         y0, y1 = j * patch_size, (j + 1) * patch_size\n",
    "    #         patches_list.append(ext_x[:, x0:x1, y0:y1])\n",
    "    #         # if len(patches_list) == 1000:\n",
    "    #         #     print(patches_list)\n",
    "    #             patches_np = np.array(patches_list)\n",
    "    #             patches = torch.Tensor(patches_list).to(device)\n",
    "                \n",
    "    #             model.eval()\n",
    "    #             with torch.no_grad():\n",
    "    #                 prediction = model(patches).to(device)\n",
    "    #                 # predicted_class = torch.argmax(prediction)\n",
    "                \n",
    "    #             predictions_list.append(prediction.detach().cpu().numpy())\n",
    "    #             # predicted_classes_list.append(predicted_class.detach().cpu().numpy())\n",
    "    #             patches_list.clear()\n",
    "    #             torch.cuda.empty_cache()\n",
    "\n",
    "    # if patches_list:\n",
    "    #     patches_np = np.array(patches_list)\n",
    "    #     patches = torch.Tensor(patches_list).to(device)\n",
    "        \n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     prediction = model(patches).to(device)\n",
    "    #     predicted_class = torch.argmax(prediction)\n",
    "        \n",
    "    # predictions_list.append(prediction.detach().cpu().numpy())\n",
    "    # # predicted_classes_list.append(predicted_class.detach().cpu().numpy())\n",
    "    # torch.cuda.empty_cache()\n",
    "\n",
    "    # predictions = np.concatenate(predictions_list, axis=0)\n",
    "    # # predicted_classes = np.concatenate(predicted_classes_list, axis=0)\n",
    "\n",
    "    # return prediction.detach().cpu().numpy()\n",
    "\n",
    "    for i in range(nb_patches_vertical):\n",
    "        for j in range(nb_patches_horizontal):\n",
    "            x0, x1 = i * patch_size, (i + 1) * patch_size\n",
    "            y0, y1 = j * patch_size, (j + 1) * patch_size\n",
    "            patches_list.append(ext_x[:, x0:x1, y0:y1])\n",
    "\n",
    "    patches = torch.Tensor(patches_list).to(device)\n",
    "    print(patches.shape)\n",
    "    model.eval()\n",
    "    prediction = model(patches)\n",
    "    # predicted_class = torch.argmax(prediction)\n",
    "\n",
    "    return prediction.detach().cpu().numpy()\n",
    "    \n",
    "device = 'cuda:3'    \n",
    "model= UNet(NB_BANDS, NB_CLASSES).to(device)  \n",
    "# model = UNet(num_classes=3, in_channels=122, depth=6, merge_mode='concat').to(device)   \n",
    "# model = UNet(num_classes=3).to(device)\n",
    "id = 1\n",
    "model.load_state_dict(torch.load('unet_model.pth'))\n",
    "model.to(device)\n",
    "predictions = predict(X_TEST[0], model, PATCH_SIZE, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0,0,0,0] + predictions[0,1,0,0] + predictions[0,2,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "returns an RGB image with color-coded classes based on mask\n",
    "\n",
    "mask: mask of shape (height, width, nb_classes)\n",
    "\"\"\"\n",
    "def picture_from_mask(mask, threshold=0):\n",
    "    colors = {\n",
    "        0: [0, 0, 255], \n",
    "        1: [255, 0, 0],   \n",
    "        2: [0, 255, 0],     \n",
    "    }\n",
    "    z_order = {\n",
    "        1: 0,\n",
    "        2: 1,\n",
    "        3: 2,\n",
    "    }\n",
    "\n",
    "    pict = 255 * np.ones((3, mask.shape[1], mask.shape[2]), dtype=np.uint8)\n",
    "    for i in range(1, 4):\n",
    "        cl = z_order[i]\n",
    "        for ch in range(3):\n",
    "            pict[ch, :, :][mask[cl, :, :] > threshold] = colors[cl][ch]\n",
    "    return pict\n",
    "\n",
    "def plot_images(images, num_cols=4):\n",
    "    num_images = images.shape[0]\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 3, num_rows * 3))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < num_images:\n",
    "            ax.imshow(images[i].transpose(1, 2, 0))  # Transpose to (height, width, channels)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')  # Hide axes for empty subplots\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def get_color_map(mask, threshold):\n",
    "    mask = np.abs(mask)\n",
    "    deficient = np.where(mask[0] > threshold, 1, 0)\n",
    "    sufficient = np.where(mask[1] > 0.5, 1, 0)\n",
    "    excessive = np.where(mask[2] > 0.124, 1, 0)\n",
    "    return deficient, sufficient, excessive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 3, 224, 224)\n",
      "predictions: [[1.5254624e-03 1.3771344e-03 1.3206626e-03 ... 1.0000000e+00\n",
      "  9.9999988e-01 9.9999988e-01]\n",
      " [4.4807611e-04 3.3171690e-04 3.4483543e-04 ... 1.0000000e+00\n",
      "  1.0000000e+00 1.0000000e+00]\n",
      " [6.3128922e-05 2.3789920e-05 2.1519640e-05 ... 1.0000000e+00\n",
      "  1.0000000e+00 1.0000000e+00]\n",
      " ...\n",
      " [8.0745034e-05 7.6473434e-06 2.0294547e-06 ... 2.5201298e-06\n",
      "  4.7619114e-06 1.1113195e-05]\n",
      " [9.9767181e-05 9.1504062e-06 2.1200622e-06 ... 3.6218605e-06\n",
      "  6.2448453e-06 1.4530690e-05]\n",
      " [5.9507831e-05 4.8669731e-06 1.5187954e-06 ... 2.6779708e-06\n",
      "  5.7032184e-06 1.2179824e-05]]\n",
      "labels: [[[  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]]\n",
      "\n",
      " [[  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]\n",
      "\n",
      " [[  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  [  0   0   0 ... 255 255 255]\n",
      "  ...\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]\n",
      "  [  0   0   0 ...   0   0   0]]]\n"
     ]
    }
   ],
   "source": [
    "# predictions = predictions.transpose(0, 3, 2, 1)\n",
    "preds = predictions\n",
    "print(preds.shape)\n",
    "# print(preds_class)\n",
    "img_height = test_img.shape[1]\n",
    "img_width =  test_img.shape[2]\n",
    "nb_channels = test_img.shape[0]\n",
    "\n",
    "nb_patches_vertical = math.ceil(img_height / PATCH_SIZE)\n",
    "nb_patches_horizontal = math.ceil(img_width / PATCH_SIZE)\n",
    "extended_height = PATCH_SIZE * nb_patches_vertical\n",
    "extended_width = PATCH_SIZE * nb_patches_horizontal\n",
    "ext_x = np.zeros((nb_channels, extended_height, extended_width), dtype=np.float32)\n",
    "\n",
    "    # model.predict() requires a numpy array\n",
    "np_predictions = np.zeros((3,extended_height, extended_width), dtype=np.float32)\n",
    "count = 0 \n",
    "for k in range(preds.shape[0]):\n",
    "    # print(preds[k].shape)\n",
    "    # count += 1 \n",
    "    i = k // nb_patches_horizontal  # Corrected: vertical index\n",
    "    j = k % nb_patches_horizontal   # Corrected: horizontal index\n",
    "    x0, x1 = i * PATCH_SIZE, (i + 1) * PATCH_SIZE\n",
    "    y0, y1 = j * PATCH_SIZE, (j + 1) * PATCH_SIZE\n",
    "    # print(x0, x1, y0, y1)\n",
    "    # print(count)\n",
    "    # print(np_predictions.shape)\n",
    "    np_predictions[:, x0:x1, y0:y1] = preds[k]\n",
    "final_predictions = np_predictions[:, :img_height, :img_width]\n",
    "# final_predictions = finals.transpose([1,2,0])\n",
    "# print(final_predictions.shape, test_mask.shape)\n",
    "print(f\"predictions: {final_predictions[0]}\")\n",
    "print(f\"labels: {Y_TEST[0]}\")\n",
    "# plt.imshow(np.abs(255*(final_predictions)).astype('uint8'))\n",
    "# print(preds)\n",
    "# u, c = np.unique(test_mask[1], return_counts=True)\n",
    "# print(dup)\n",
    "# print(np.abs(final_predictions[0]))\n",
    "# print(test_mask[2])\n",
    "map_ = picture_from_mask(final_predictions, 0.2)\n",
    "class1, class2, class3 = get_color_map(final_predictions, 0.7)\n",
    "# print(class1)\n",
    "# print(class2)\n",
    "# print(np.min(final_predictions[0]))\n",
    "# print(map_[2])\n",
    "# tiff.imwrite('class1.tif', class1)\n",
    "# # tiff.imwrite('map.tif',map_)\n",
    "# tiff.imwrite('result.tif', (255*(final_predictions)).astype('uint8'))\n",
    "# tiff.imwrite('y_test.tif', test_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 551, 1780)\n"
     ]
    }
   ],
   "source": [
    "print(final_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findmax(a,b,c):\n",
    "    if (a>b) and (a>c):\n",
    "        return a\n",
    "    elif (b>a) and (b>c):\n",
    "        return b\n",
    "    else:\n",
    "        return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros([final_predictions.shape[0], final_predictions.shape[1], final_predictions.shape[2]], dtype=np.float32)\n",
    "for i in range(final_predictions.shape[2]):\n",
    "    for j in range(final_predictions.shape[1]):\n",
    "        max = findmax(final_predictions[0,j,i],final_predictions[1,j,i],final_predictions[2,j,i])\n",
    "        if max == final_predictions[0,j,i]:\n",
    "            predictions[0,j,i] = 1\n",
    "            predictions[1,j,i] = 0\n",
    "            predictions[2,j,i] = 0\n",
    "\n",
    "        elif max == final_predictions[1,j,i]:\n",
    "            predictions[1,j,i] = 1\n",
    "            predictions[0,j,i] = 0\n",
    "            predictions[2,j,i] = 0   \n",
    "\n",
    "        elif max == final_predictions[2,j,i]:\n",
    "            predictions[2,j,i] = 1 \n",
    "            predictions[1,j,i] = 0\n",
    "            predictions[0,j,i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"predictions: {predictions}\")                \n",
    "# print(f\"test mask: {Y_TEST[0]}\")\n",
    "# # for i in range (3):\n",
    "#     for j in range(725):\n",
    "#         accuracy_score(predictions[i], test_mask[i])\n",
    "#         print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 988.8x604.8 with 1 Axes>,\n",
       " <Axes: >,\n",
       " <matplotlib.image.AxesImage at 0x7f27381a7560>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 988.8x604.8 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 988.8x604.8 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label = tiff.imread('y_test.tif')\n",
    "# map = tiff.imread('map.tif')\n",
    "# result = tiff.imread('result.tif')\n",
    "\n",
    "tiff.imshow(255*(predictions).astype('uint8'))\n",
    "tiff.imshow(Y_TEST[0])\n",
    "# tiff.imwriet('test',test_img)\n",
    "# tiff.imwrite('prediction2.tif',255*(predictions).astype('uint8'))\n",
    "\n",
    "# tiff.imshow(CR)\n",
    "# tiff.imshow(result)\n",
    "# tiff.imshow(map)\n",
    "# tiff.imshow(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
